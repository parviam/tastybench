,paperId,title,total_citations,a,b,R2,lead_author_id,last_author_id,citation_dates,citation_counts,lead_author_h_index,last_author_h_index,rank
0,dd4cfde3e135f799a9a71b4f57e13a29de89f7e3,DAPO: An Open-Source LLM Reinforcement Learning System at Scale,721,-8.78571428571423,90.07142857142857,0.9826042840758538,23716915,2285763682,"[""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[20, 53, 180, 263, 327, 420, 567]",9.0,5.0,1
1,668075792a7ab40457d92e09da28d35c879271c3,Kimi k1.5: Scaling Reinforcement Learning with LLMs,579,-23.644444444444304,68.63333333333333,0.9765029390808693,2341539673,2341579297,"[""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[10, 35, 81, 137, 270, 356, 409, 452, 508]",1.0,2.0,2
2,143e18bfd7c356592e7c1439738a3525d3e16279,Does Reinforcement Learning Really Incentivize Reasoning Capacity in LLMs Beyond the Base Model?,354,26.238095238095255,53.17142857142856,0.987134710164721,2256993684,2350439231,"[""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[15, 81, 149, 193, 225, 292]",9.0,2.0,3
3,1fcaafeb72142fe3d1a5d698a072d69778d244b0,Search-R1: Training LLMs to Reason and Leverage Search Engines with Reinforcement Learning,403,0.3214285714286083,48.46428571428571,0.9864200771373474,2266752881,2257136881,"[""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[17, 32, 102, 143, 181, 242, 303]",3.0,10.0,4
4,f2d0f3d47ae850f49a58f4977393bd0025af4bec,HybridFlow: A Flexible and Efficient RLHF Framework,666,-102.80219780219774,41.005494505494504,0.7989634115167368,2268673684,2318983809,"[""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[7, 9, 9, 11, 12, 19, 34, 66, 188, 266, 313, 398, 530]",4.0,2.0,5
5,53a803388e83ae89261624099d7be4287ace67cb,"DeepSeek-V2: A Strong, Economical, and Efficient Mixture-of-Experts Language Model",736,-27.50980392156856,39.83578431372548,0.9780426507442987,144485528,2238628841,"[""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[25, 54, 72, 90, 109, 153, 184, 217, 240, 300, 354, 396, 455, 515, 546, 594, 646]",14.0,11.0,6
6,34471a2fa18ea22efad5287cf4aeb18542c98a9b,DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning,4277,-77.46666666666657,33.19999999999999,0.29999999999999993,2307073216,2329999671,"[""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[0, 0, 0, 0, 0, 0, 0, 0, 498]",3.0,4.0,7
7,28c6ac721f54544162865f41c5692e70d61bccab,A Survey on Large Language Model based Autonomous Agents,1780,-210.02564102564102,32.48205128205129,0.715545632769071,2152509786,153693432,"[""2023-09-01"", ""2023-10-01"", ""2023-11-01"", ""2023-12-01"", ""2024-01-01"", ""2024-02-01"", ""2024-03-01"", ""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 28, 80, 142, 172, 263, 350, 425, 544, 643, 723, 816, 910]",6.0,53.0,8
8,f82f49c20c6acc69f884f05e3a9f1ceea91061ce,Detecting hallucinations in large language models using semantic entropy,624,-65.4313725490195,32.38480392156862,0.9318715892706148,33859827,2303846295,"[""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[15, 18, 21, 31, 41, 78, 98, 118, 134, 171, 217, 254, 317, 373, 415, 466, 525]",22.0,5.0,9
9,f5d194b600e4e4021564f3647afde07308ac41d3,VLM-R1: A Stable and Generalizable R1-style Large Vision-Language Model,225,49.33333333333332,30.999999999999993,0.9428523373917269,2174678931,8200875,"[""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[28, 95, 128, 144, 168, 198]",6.0,20.0,10
10,d6a29be03a0497602e89311ec38e5141335647c5,Beyond the 80/20 Rule: High-Entropy Minority Tokens Drive Effective Reinforcement Learning for LLM Reasoning,157,7.900000000000018,29.4,0.927027027027027,2219056193,2326803484,"[""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[16, 31, 55, 106]",10.0,10.0,11
11,ae736662f64d56f3ab1894fbd9c45f8f37251843,OpenAssistant Conversations - Democratizing Large Language Model Alignment,725,-8.552688172043016,23.73236929922136,0.9925647662654669,3996967,102888911,"[""2023-05-01"", ""2023-06-01"", ""2023-07-01"", ""2023-08-01"", ""2023-09-01"", ""2023-10-01"", ""2023-11-01"", ""2023-12-01"", ""2024-01-01"", ""2024-02-01"", ""2024-03-01"", ""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[8, 25, 40, 49, 63, 78, 119, 148, 162, 183, 226, 256, 288, 323, 347, 376, 391, 406, 450, 464, 479, 489, 516, 537, 554, 589, 606, 615, 634, 646]",8.0,3.0,12
12,16f01c1b3ddd0b2abd5ddfe4fdb3f74767607277,Time-LLM: Time Series Forecasting by Reprogramming Large Language Models,582,-43.483333333333256,21.69782608695652,0.9759147298786655,2254096428,2253561592,"[""2023-11-01"", ""2023-12-01"", ""2024-01-01"", ""2024-02-01"", ""2024-03-01"", ""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[11, 13, 15, 26, 50, 57, 62, 98, 122, 135, 151, 166, 203, 222, 242, 255, 279, 317, 337, 377, 410, 428, 463, 506]",10.0,11.0,13
13,16f01c1b3ddd0b2abd5ddfe4fdb3f74767607277,Time-LLM: Time Series Forecasting by Reprogramming Large Language Models,582,-43.483333333333256,21.69782608695652,0.9759147298786655,2254096428,2253561592,"[""2023-11-01"", ""2023-12-01"", ""2024-01-01"", ""2024-02-01"", ""2024-03-01"", ""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[11, 13, 15, 26, 50, 57, 62, 98, 122, 135, 151, 166, 203, 222, 242, 255, 279, 317, 337, 377, 410, 428, 463, 506]",10.0,11.0,14
14,0671fd553dd670a4e820553a974bc48040ba0819,Reflexion: language agents with verbal reinforcement learning,1860,-179.74395161290323,21.26895161290323,0.5789601930767644,2212367248,47188964,"[""2023-04-01"", ""2023-05-01"", ""2023-06-01"", ""2023-07-01"", ""2023-08-01"", ""2023-09-01"", ""2023-10-01"", ""2023-11-01"", ""2023-12-01"", ""2024-01-01"", ""2024-02-01"", ""2024-03-01"", ""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 25, 69, 100, 184, 269, 353, 471, 584, 652, 745, 866]",6.0,18.0,15
15,69535d3c6ff3238f8e7b2b29c1d40ea9d9d7914f,Reasoning with Exploration: An Entropy Perspective,93,-0.09999999999998738,19.900000000000002,0.9470524931244768,2068324576,2253471545,"[""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[5, 15, 34, 65]",8.0,15.0,16
16,1122b654f8b47c1aa9c04ff6bbe7561c798e2ad0,Reinforcement Learning for Reasoning in Large Language Models with One Training Example,128,11.333333333333321,18.999999999999996,0.9769078116543388,2334890311,2324671790,"[""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[4, 33, 55, 74, 85, 102]",7.0,4.0,17
17,c4ff8bc44d88cd267baf18ac5d3a3a1fe86d08eb,Training Language Models to Self-Correct via Reinforcement Learning,256,-13.604395604395615,18.895604395604398,0.9523359394149635,2317038858,2258552654,"[""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[10, 25, 25, 30, 38, 60, 83, 105, 145, 179, 184, 196, 217]",4.0,5.0,18
18,446c3356b95a29dca4b908533c088ce63f2275cb,Logic-RL: Unleashing LLM Reasoning with Rule-Based Reinforcement Learning,134,0.41666666666665125,18.02380952380952,0.965470125213969,2346416801,2346626409,"[""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[2, 14, 24, 64, 85, 94, 104, 121]",3.0,2.0,19
19,446c3356b95a29dca4b908533c088ce63f2275cb,Logic-RL: Unleashing LLM Reasoning with Rule-Based Reinforcement Learning,134,0.41666666666665125,18.02380952380952,0.965470125213969,2346416801,2346626409,"[""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[2, 14, 24, 64, 85, 94, 104, 121]",3.0,2.0,20
20,3487c12512fa41d3a4d64f00cb842525a8590ad3,TALLRec: An Effective and Efficient Tuning Framework to Align Large Language Model with Recommendation,477,-43.36774193548385,15.459844271412683,0.9801172216396765,2188063534,7792071,"[""2023-05-01"", ""2023-06-01"", ""2023-07-01"", ""2023-08-01"", ""2023-09-01"", ""2023-10-01"", ""2023-11-01"", ""2023-12-01"", ""2024-01-01"", ""2024-02-01"", ""2024-03-01"", ""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[3, 7, 11, 18, 24, 28, 42, 53, 65, 71, 89, 115, 128, 144, 161, 174, 194, 208, 233, 243, 252, 267, 287, 295, 325, 352, 374, 401, 422, 438]",11.0,95.0,21
21,a4f374a96e9d265a03e2e2cdd7e204e1e4e37416,CosyVoice 2: Scalable Streaming Speech Synthesis with Large Language Models,171,-17.490909090909064,13.975757575757573,0.8695068358576592,2325844336,2331310825,"[""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[4, 4, 10, 14, 21, 41, 55, 71, 92, 142]",5.0,1.0,22
22,600ff4c4ae9fc506c86673c5ecce4fa90803e987,RLAIF vs. RLHF: Scaling Reinforcement Learning from Human Feedback with AI Feedback,435,8.47008547008554,13.725470085470088,0.988906538538061,2132475367,2188497,"[""2023-09-01"", ""2023-10-01"", ""2023-11-01"", ""2023-12-01"", ""2024-01-01"", ""2024-02-01"", ""2024-03-01"", ""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[9, 19, 31, 45, 51, 64, 95, 112, 128, 147, 164, 179, 185, 188, 202, 209, 216, 222, 239, 256, 270, 296, 317, 330, 342, 365]",5.0,20.0,23
23,182c7b40ff7560a5545764814338f55a2098e441,Reinforced Self-Training (ReST) for Language Modeling,345,-0.17948717948714787,12.749743589743591,0.9939214339041706,146372255,1737568,"[""2023-09-01"", ""2023-10-01"", ""2023-11-01"", ""2023-12-01"", ""2024-01-01"", ""2024-02-01"", ""2024-03-01"", ""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[4, 14, 23, 30, 37, 50, 73, 91, 110, 121, 142, 146, 154, 158, 188, 196, 206, 214, 230, 244, 256, 278, 283, 291, 295, 305]",15.0,76.0,24
24,9a75e23639bfcc3a51da57a3b682a984d1d8ac0b,Language Models can Solve Computer Tasks,422,-12.877016129032254,12.626209677419356,0.99660398681451,2176466425,143953836,"[""2023-04-01"", ""2023-05-01"", ""2023-06-01"", ""2023-07-01"", ""2023-08-01"", ""2023-09-01"", ""2023-10-01"", ""2023-11-01"", ""2023-12-01"", ""2024-01-01"", ""2024-02-01"", ""2024-03-01"", ""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[2, 6, 21, 29, 37, 48, 56, 71, 83, 89, 100, 114, 140, 152, 165, 188, 196, 199, 210, 232, 237, 248, 259, 274, 292, 306, 316, 338, 344, 355, 365]",3.0,19.0,25
25,1d03586baa32b3d6ff657a180053821543e11abb,RAGEN: Understanding Self-Evolution in LLM Agents via Multi-Turn Reinforcement Learning,91,6.52380952380952,11.857142857142854,0.9438106807200854,2243360876,3361240,"[""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[2, 25, 34, 37, 49, 70]",7.0,13.0,26
26,900cd128482bbab4d2752d01ce80c55498b78dd2,SWE-RL: Advancing LLM Reasoning via Reinforcement Learning on Open Software Evolution,97,3.499999999999991,10.928571428571425,0.9805912004133097,2237736409,2324830843,"[""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[5, 13, 21, 42, 50, 54, 66, 83]",8.0,2.0,27
27,10feab31bb9e71a0f1094fb00c0554abfb992c4d,ProRL: Prolonged Reinforcement Learning Expands Reasoning Boundaries in Large Language Models,70,-0.19999999999999063,10.8,0.9033457249070632,2369203659,2359888593,"[""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[4, 10, 17, 26, 50]",2.0,4.0,28
28,e8df1cf6742b50a15500b8dd3dde3942e9c91418,Alphazero-like Tree-Search can Guide Large Language Model Decoding and Training,259,-44.304615384615374,10.135384615384615,0.8737181017131272,1443767933,2256981980,"[""2023-10-01"", ""2023-11-01"", ""2023-12-01"", ""2024-01-01"", ""2024-02-01"", ""2024-03-01"", ""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[0, 2, 4, 5, 6, 10, 13, 15, 21, 29, 32, 35, 41, 54, 62, 71, 79, 107, 136, 156, 182, 203, 214, 221, 235]",12.0,7.0,29
29,4aef44e4aeaf28868ae2f1fff2c4eb19ff4df1f6,The Unreasonable Effectiveness of Entropy Minimization in LLM Reasoning,65,3.200000000000002,10.0,0.9444654325651681,1923351,2334095077,"[""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[6, 13, 20, 29, 48]",13.0,5.0,30
30,1414653547b72a23d2c0ca987d270fb236c9105a,On the Generalization of SFT: A Reinforcement Learning Perspective with Reward Rectification,21,2.9999999999999996,9.999999999999996,1.0,2290907197,2366165580,"[""2025-09-01"", ""2025-10-01""]","[3, 13]",5.0,1.0,31
31,dfbfa21a93c3164ae8a033398c8de42b03b1b84d,ChatGPT Beyond English: Towards a Comprehensive Evaluation of Large Language Models in Multilingual Learning,321,6.369892473118298,9.406674082313684,0.9946774471511779,1405279380,1811211,"[""2023-05-01"", ""2023-06-01"", ""2023-07-01"", ""2023-08-01"", ""2023-09-01"", ""2023-10-01"", ""2023-11-01"", ""2023-12-01"", ""2024-01-01"", ""2024-02-01"", ""2024-03-01"", ""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[5, 20, 25, 32, 38, 48, 59, 68, 75, 81, 98, 111, 124, 134, 151, 158, 164, 172, 184, 189, 200, 204, 211, 223, 232, 242, 249, 259, 261, 266]",16.0,39.0,32
32,6f9dbae279fa0c3a90d12f3b0f271dc8e6274817,A Survey of Reinforcement Learning from Human Feedback,224,-17.802371541501973,9.210615471485035,0.9699413316772286,2276205601,1691955,"[""2024-01-01"", ""2024-02-01"", ""2024-03-01"", ""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[0, 2, 8, 10, 17, 27, 35, 47, 50, 58, 69, 77, 84, 88, 97, 105, 117, 143, 159, 170, 178, 195]",3.0,68.0,33
33,4829b73a47be18f73e9e8d90f3c23c8f84d0fccb,Representation Learning with Large Language Models for Recommendation,248,-19.06999999999999,9.190869565217392,0.9508373865433233,2163180478,2261248317,"[""2023-11-01"", ""2023-12-01"", ""2024-01-01"", ""2024-02-01"", ""2024-03-01"", ""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[9, 10, 13, 15, 23, 27, 30, 38, 43, 47, 56, 61, 81, 87, 97, 104, 118, 128, 148, 161, 170, 187, 207, 219]",10.0,13.0,34
34,b46d05bcf42295b872f3cebf875643d2e66496a4,Direct Language Model Alignment from Online AI Feedback,194,1.9571428571428746,8.999248120300752,0.9920250875351218,2283016358,2281742464,"[""2024-03-01"", ""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[5, 7, 15, 32, 44, 51, 52, 65, 80, 84, 88, 89, 106, 118, 127, 141, 153, 159, 163, 170]",2.0,6.0,35
35,91206346edbe28abb606d7b3425cd455d4019d4f,Scaling Relationship on Learning Mathematical Reasoning with Large Language Models,258,-9.418803418803384,8.735042735042736,0.9730347582842159,2112340945,2192678144,"[""2023-09-01"", ""2023-10-01"", ""2023-11-01"", ""2023-12-01"", ""2024-01-01"", ""2024-02-01"", ""2024-03-01"", ""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[6, 12, 22, 22, 25, 32, 44, 47, 54, 62, 76, 82, 88, 92, 109, 111, 119, 125, 136, 143, 153, 187, 199, 208, 213, 227]",20.0,12.0,36
36,d6fa3cfde46c45d746853b39d7cc420ec96d8f97,Kimina-Prover Preview: Towards Large Formal Reasoning Models with Reinforcement Learning,61,4.904761904761904,8.57142857142857,0.9910438995742181,2355444997,2355564671,"[""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[4, 14, 22, 33, 37, 48]",4.0,3.0,37
37,89c3f847ded8200d1a1d09e278bb32fd721c9761,AReaL: A Large-Scale Asynchronous Reinforcement Learning System for Language Reasoning,48,-4.599999999999993,8.5,0.8692252165543792,2261284978,2261359927,"[""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[1, 1, 7, 18, 35]",6.0,6.0,38
38,f849c93a4cbf7fb5f8fbe32b8c607beeb6cea837,GPG: A Simple and Strong Reinforcement Learning Baseline for Model Reasoning,58,6.714285714285711,7.914285714285713,0.9324785805432338,2315809917,2331897059,"[""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[2, 20, 25, 30, 34, 48]",4.0,3.0,39
39,d318e0169f649656c71f02a1f84194a734fe1962,Reward Design with Language Models,256,-16.249999999999993,7.84274193548387,0.993067213379412,37909625,1779671,"[""2023-03-01"", ""2023-04-01"", ""2023-05-01"", ""2023-06-01"", ""2023-07-01"", ""2023-08-01"", ""2023-09-01"", ""2023-10-01"", ""2023-11-01"", ""2023-12-01"", ""2024-01-01"", ""2024-02-01"", ""2024-03-01"", ""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[2, 2, 3, 9, 17, 20, 26, 34, 41, 46, 53, 61, 76, 86, 92, 103, 108, 116, 120, 130, 150, 154, 156, 158, 164, 178, 185, 199, 209, 216, 224, 232]",10.0,61.0,40
40,9bf00afb0efb02a263fa3ddea1e768677498536c,Personalized Soups: Personalized Large Language Model Alignment via Post-hoc Parameter Merging,193,-14.503333333333318,7.808260869565219,0.988430530244115,2000091730,2233163820,"[""2023-11-01"", ""2023-12-01"", ""2024-01-01"", ""2024-02-01"", ""2024-03-01"", ""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[2, 2, 6, 6, 14, 17, 24, 35, 48, 54, 61, 65, 80, 85, 90, 94, 109, 120, 127, 141, 147, 152, 157, 171]",16.0,4.0,41
41,8fd11c6f3eb1d0aeb915369f3c4f0b1bb24cab0c,Large Language Model Unlearning,195,-18.83333333333331,7.673913043478261,0.9731634545567573,2257134957,2279671647,"[""2023-11-01"", ""2023-12-01"", ""2024-01-01"", ""2024-02-01"", ""2024-03-01"", ""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[1, 2, 2, 3, 8, 15, 21, 28, 41, 48, 53, 58, 74, 79, 85, 85, 94, 100, 110, 126, 145, 154, 162, 172]",7.0,5.0,42
42,0d1c76d45afa012ded7ab741194baf142117c495,Direct Preference Optimization: Your Language Model is Secretly a Reward Model,5725,-62.85517241379305,7.098029556650245,0.1884313744389241,102801230,46881670,"[""2023-06-01"", ""2023-07-01"", ""2023-08-01"", ""2023-09-01"", ""2023-10-01"", ""2023-11-01"", ""2023-12-01"", ""2024-01-01"", ""2024-02-01"", ""2024-03-01"", ""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 48, 321, 690]",23.0,89.0,43
43,bde841b0dbbf7a15ee69966a828c7fe2cf532ad9,WebRL: Training LLM Web Agents via Self-Evolving Online Curriculum Reinforcement Learning,81,-8.772727272727268,7.045454545454544,0.9297600619195047,2286747770,2243402027,"[""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[1, 3, 4, 8, 11, 14, 33, 44, 49, 57, 67]",6.0,32.0,44
44,1c66c41ff22adf66bb9b06d87d5a2ab7b8ee8de7,"Large Language Model (LLM) for Telecommunications: A Comprehensive Survey on Principles, Key Techniques, and Opportunities",134,-9.607843137254875,7.0098039215686265,0.9390958521620927,2302316320,2302284624,"[""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[4, 4, 9, 12, 15, 24, 31, 35, 37, 40, 47, 53, 76, 88, 96, 102, 117]",6.0,2.0,45
45,04c05c6acc970f2ca89af8e436b8dd8189396146,General-Reasoner: Advancing LLM Reasoning Across All Domains,50,6.000000000000002,6.8999999999999995,0.9943609022556391,2461713,2249847177,"[""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[7, 12, 19, 27, 34]",22.0,18.0,46
46,6b34d9f4a91670a265ce51ce4be71cdbf8e15d05,LLM Post-Training: A Deep Dive into Reasoning Large Language Models,55,2.999999999999995,6.749999999999997,0.9754061803122014,2348317787,2242949919,"[""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[2, 9, 14, 25, 35, 38, 43, 47]",2.0,16.0,47
47,fc84f5b58e68871f3d6889dc2a93dffa7e107be2,Okapi: Instruction-tuned Large Language Models in Multiple Languages with Reinforcement Learning from Human Feedback,179,-24.39947089947089,6.631868131868134,0.9649590403980294,1405279380,1811211,"[""2023-08-01"", ""2023-09-01"", ""2023-10-01"", ""2023-11-01"", ""2023-12-01"", ""2024-01-01"", ""2024-02-01"", ""2024-03-01"", ""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[1, 1, 1, 1, 1, 3, 6, 14, 16, 19, 25, 41, 47, 55, 59, 77, 84, 88, 91, 104, 112, 118, 130, 137, 142, 146, 150]",16.0,39.0,48
48,8e3b1f5d8b6c165f64137cc1f7dea89cf6f622bd,d1: Scaling Reasoning in Diffusion Large Language Models via Reinforcement Learning,55,-1.0952380952380938,6.571428571428569,0.9291569086651054,2260172378,2267723293,"[""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[1, 6, 11, 16, 21, 37]",6.0,3.0,49
49,f7749635a5fc0492ef4705bee963ffa887bb2865,Fine-Tuning Large Vision-Language Models as Decision-Making Agents via Reinforcement Learning,116,-10.588235294117633,6.558823529411763,0.9205721373080175,119692515,2268967207,"[""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[4, 6, 10, 11, 14, 17, 19, 25, 29, 32, 44, 56, 74, 82, 88, 95, 106]",16.0,9.0,50
50,bd0cd89337cc40d39d3a4cbe9c8709e06e877f3e,Continual Learning for Large Language Models: A Survey,148,5.91428571428572,6.466917293233083,0.990894064983009,1514917592,2561045,"[""2024-03-01"", ""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[7, 11, 18, 24, 35, 39, 44, 50, 63, 70, 70, 72, 79, 84, 92, 101, 117, 119, 123, 129]",7.0,43.0,51
51,89e184d2bc830af568e439db9476caa0c047e11a,Guiding Pretraining in Reinforcement Learning with Large Language Models,215,-12.312500000000016,6.465725806451612,0.9920578958879251,144894286,2112400,"[""2023-03-01"", ""2023-04-01"", ""2023-05-01"", ""2023-06-01"", ""2023-07-01"", ""2023-08-01"", ""2023-09-01"", ""2023-10-01"", ""2023-11-01"", ""2023-12-01"", ""2024-01-01"", ""2024-02-01"", ""2024-03-01"", ""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[1, 3, 3, 8, 12, 16, 23, 27, 36, 38, 46, 51, 63, 69, 74, 85, 92, 100, 103, 111, 129, 134, 137, 139, 139, 147, 151, 164, 171, 174, 179, 188]",16.0,51.0,52
52,69e6dd39bf13d290fb9d885da90cc037f0dd2975,Audio Flamingo: A Novel Audio Language Model with Few-Shot Learning and Dialogue Abilities,135,-9.742857142857131,6.457142857142857,0.9813884439266702,2229373549,2264406909,"[""2024-03-01"", ""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[1, 2, 3, 4, 14, 20, 24, 35, 48, 50, 54, 57, 60, 68, 74, 87, 95, 102, 113, 121]",8.0,26.0,53
53,a50d4fd8f584276c0fd8560255884edd57aa926e,Zhongjing: Enhancing the Chinese Medical Capabilities of Large Language Model through Expert Feedback and Real-world Multi-turn Dialogue,168,-20.068376068376043,6.417777777777778,0.9548831691496101,2193154278,144539290,"[""2023-09-01"", ""2023-10-01"", ""2023-11-01"", ""2023-12-01"", ""2024-01-01"", ""2024-02-01"", ""2024-03-01"", ""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[1, 1, 5, 8, 10, 10, 14, 18, 22, 26, 37, 40, 44, 49, 62, 66, 76, 79, 92, 99, 106, 124, 135, 142, 148, 150]",3.0,9.0,54
54,82f59319e581cdfe16a97fe29bec6215ad818a81,Learning What Reinforcement Learning Can't: Interleaved Online Fine-Tuning for Hardest Questions,29,1.9,6.4,0.9799043062200957,2300236632,2309265357,"[""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[3, 7, 14, 22]",2.0,8.0,55
55,0b58f4ec8cbf6f63fb65b7e3c368cf511eadecd3,Grounding Large Language Models in Interactive Environments with Online Reinforcement Learning,216,-10.926136363636337,6.061766862170087,0.9929416534991762,2003745905,1720664,"[""2023-03-01"", ""2023-04-01"", ""2023-05-01"", ""2023-06-01"", ""2023-07-01"", ""2023-08-01"", ""2023-09-01"", ""2023-10-01"", ""2023-11-01"", ""2023-12-01"", ""2024-01-01"", ""2024-02-01"", ""2024-03-01"", ""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[1, 3, 6, 13, 17, 19, 21, 26, 32, 40, 47, 52, 57, 65, 72, 79, 83, 90, 93, 98, 111, 115, 121, 124, 130, 143, 149, 159, 167, 168, 174, 182]",3.0,54.0,56
56,529ff7d6441d244212cf2becafd12a7e67ac56d9,FederatedScope-LLM: A Comprehensive Package for Fine-tuning Large Language Models in Federated Learning,172,-13.675213675213664,6.010940170940172,0.9612131445028399,2162042348,2237499232,"[""2023-09-01"", ""2023-10-01"", ""2023-11-01"", ""2023-12-01"", ""2024-01-01"", ""2024-02-01"", ""2024-03-01"", ""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[4, 4, 7, 10, 14, 18, 21, 24, 27, 32, 41, 45, 47, 54, 62, 69, 74, 81, 86, 97, 103, 115, 129, 135, 145, 154]",9.0,10.0,57
57,c78350e81298ca87bc1d59b466fa40081232caaa,Teaching Large Language Models to Reason with Reinforcement Learning,129,-4.115789473684202,5.989473684210527,0.9547514781557335,2279337437,48647153,"[""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[6, 9, 12, 17, 20, 22, 26, 38, 39, 43, 45, 52, 58, 65, 82, 96, 100, 106, 110]",6.0,27.0,58
58,7ae48b24cbf955bf9b9498fb287bf4c5cd3b73d4,OpenFedLLM: Training Large Language Models on Decentralized Private Data via Federated Learning,127,-5.942857142857136,5.888721804511279,0.971775583079063,2273620042,2111637832,"[""2024-03-01"", ""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[5, 6, 8, 14, 20, 23, 24, 30, 36, 42, 46, 52, 60, 65, 71, 81, 94, 101, 108, 114]",9.0,12.0,59
59,131a13c60f179511572abc81d6bd6aa988e96854,Rule Based Rewards for Language Model Safety,81,12.181818181818185,5.745454545454546,0.9940371310537056,2319225702,2297773848,"[""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[14, 18, 21, 30, 34, 40, 47, 55, 59, 63, 69]",4.0,5.0,60
60,e2bd895ffbe527ba9cf038fc86990c059ee33a04,Enhancing Code LLMs with Reinforcement Learning in Code Generation: A Survey,59,-1.545454545454539,5.721212121212121,0.9358234409523569,2337838507,2328256204,"[""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[6, 7, 7, 10, 14, 27, 33, 38, 45, 55]",1.0,3.0,61
61,8d6411e337502f7fe0bfa59d486803a73d2c1192,Advancing Language Model Reasoning through Reinforcement Learning and Inference Scaling,54,3.111111111111119,5.666666666666665,0.9732824427480916,2329057292,2328936204,"[""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[2, 8, 13, 19, 30, 36, 37, 41, 46]",6.0,3.0,62
62,67f03ac399693393116076c0b8ec8ea05b910685,WARM: On the Benefits of Weight Averaged Reward Models,123,11.528138528138541,5.5519480519480515,0.9809722932442351,2280134846,151047979,"[""2024-02-01"", ""2024-03-01"", ""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[6, 11, 18, 24, 32, 44, 48, 52, 59, 72, 74, 75, 78, 86, 90, 98, 102, 105, 109, 112, 113]",9.0,16.0,63
63,6c00f661c46391642208a5292f38b5a9e0e09cae,AutoWebGLM: A Large Language Model-based Web Navigating Agent,104,-11.345029239766088,5.406604747162022,0.8925102858373503,2051311700,2260595820,"[""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[1, 3, 7, 9, 11, 14, 17, 19, 22, 23, 27, 33, 48, 56, 72, 78, 87, 96]",10.0,19.0,64
64,7c16ef4e3c13265307c3569cc8f8ec5b0f7b0991,Secrets of RLHF in Large Language Models Part II: Reward Modeling,128,5.138528138528151,5.333766233766234,0.9896337156088899,2188630983,2238451522,"[""2024-02-01"", ""2024-03-01"", ""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[4, 9, 12, 18, 24, 39, 40, 43, 49, 59, 62, 64, 65, 72, 78, 81, 96, 98, 100, 104, 111]",5.0,18.0,65
65,0c43750030198dbe7fe164e1ce743ec64427bca1,Scaling Laws for Reward Model Overoptimization in Direct Alignment Algorithms,89,4.625000000000001,5.124999999999999,0.9842801738687167,2301519261,2791038,"[""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[9, 11, 13, 15, 29, 31, 33, 36, 46, 51, 52, 63, 71, 73, 74, 82]",9.0,35.0,66
66,f743287be3ced6757de7ecb26d03815b22cd737b,Query Rewriting for Retrieval-Augmented Large Language Models,153,-24.089655172413774,5.021182266009852,0.9327198435790099,2141114505,46429989,"[""2023-06-01"", ""2023-07-01"", ""2023-08-01"", ""2023-09-01"", ""2023-10-01"", ""2023-11-01"", ""2023-12-01"", ""2024-01-01"", ""2024-02-01"", ""2024-03-01"", ""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[0, 0, 0, 2, 3, 3, 3, 5, 6, 10, 12, 20, 21, 25, 32, 37, 44, 55, 67, 69, 75, 79, 86, 97, 106, 113, 118, 122, 130]",10.0,64.0,67
67,3646acd0dc49a00d38517abccfc3a54cb78bbadc,SRPO: Enhancing Multimodal LLM Reasoning via Reflection-Aware Reinforcement Learning,23,1.5000000000000022,5.0,0.9920634920634921,2347120431,2272708319,"[""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[2, 6, 11, 17]",2.0,5.0,68
68,66325b4c3b21a48e3cd49dcf6979eca8bfe59fb1,OpenR: An Open Source Framework for Advanced Reasoning with Large Language Models,55,-2.897435897435904,4.996503496503496,0.9641053444136599,2324813220,2244690305,"[""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[0, 3, 6, 6, 12, 24, 30, 37, 40, 43, 44, 50]",6.0,8.0,69
69,1a41d449f2ed4051ac4c763fb8b1b07357eaf5f4,WavLLM: Towards Robust and Adaptive Speech Large Language Model,94,-8.705263157894738,4.908771929824563,0.9550792849108578,2277450543,2277299355,"[""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[2, 2, 2, 4, 7, 10, 22, 28, 30, 32, 36, 40, 41, 44, 61, 69, 74, 85, 85]",5.0,7.0,70
70,95d638e7705ec561382268405bc488df4c26c7f7,Fin-R1: A Large Language Model for Financial Reasoning through Reinforcement Learning,37,1.3214285714285712,4.892857142857143,0.9828759949727692,2232782972,2351085693,"[""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[2, 4, 12, 17, 22, 24, 31]",3.0,1.0,71
71,668858489bbec3ce45f7a84a6a557b329f9ec91a,ArCHer: Training Language Model Agents via Hierarchical Multi-Turn RL,109,-9.714285714285698,4.890977443609023,0.936764711254043,2288585404,1488785534,"[""2024-03-01"", ""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[3, 4, 4, 7, 11, 14, 16, 17, 24, 27, 31, 33, 43, 48, 51, 63, 76, 79, 89, 95]",8.0,41.0,72
72,ac258100ebe178287ae4ae3dc7ac78f8c27e017d,Language Agents with Reinforcement Learning for Strategic Play in the Werewolf Game,117,-2.689999999999988,4.875217391304349,0.9939374193047297,2170477930,2108052575,"[""2023-11-01"", ""2023-12-01"", ""2024-01-01"", ""2024-02-01"", ""2024-03-01"", ""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[4, 5, 5, 9, 15, 21, 25, 29, 37, 44, 47, 50, 55, 59, 64, 69, 75, 79, 82, 89, 101, 104, 105, 108]",5.0,8.0,73
73,0fa9b8a28cf379360ad56b7c778ce7ffc43bea5e,LLaGA: Large Language and Graph Assistant,109,-2.428571428571419,4.5398496240601505,0.9802324394614291,2284222685,2254949434,"[""2024-03-01"", ""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[5, 6, 9, 10, 16, 19, 23, 26, 34, 35, 40, 42, 46, 55, 58, 66, 73, 76, 84, 91]",5.0,5.0,74
74,fb09b581589e1195ff018179c6a11668587c6d64,Vision-Language Models are Zero-Shot Reward Models for Reinforcement Learning,111,-7.966666666666657,4.36304347826087,0.9751274513356074,2260340085,2260338911,"[""2023-11-01"", ""2023-12-01"", ""2024-01-01"", ""2024-02-01"", ""2024-03-01"", ""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[3, 3, 4, 6, 9, 14, 15, 19, 24, 28, 28, 34, 43, 47, 49, 50, 56, 66, 73, 81, 86, 89, 90, 96]",2.0,1.0,75
75,1f45c9d4d92c51a94c984eb4c2c6e027bbf78038,SRPO: A Cross-Domain Implementation of Large-Scale Reinforcement Learning on LLM,33,5.809523809523805,4.342857142857142,0.9669642857142857,2356633495,2356584590,"[""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[4, 11, 15, 21, 23, 26]",2.0,2.0,76
76,4f0e4a313a3f777b4b6aab4f364b9bc51a6aacc9,Unlocking Efficient Long-to-Short LLM Reasoning with Model Merging,33,4.357142857142858,4.214285714285714,0.9789088863892014,2346255376,2347282055,"[""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[5, 7, 15, 16, 20, 26, 30]",4.0,4.0,77
77,24d9d00b91f99dde3c9a0ea5c79e63f2ed26151c,Reinforcing General Reasoning without Verifiers,28,-0.9999999999999967,4.2,0.7194127243066883,2257107372,2356268297,"[""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[1, 4, 5, 6, 21]",5.0,4.0,78
78,dd416e705a68419edb1cb840a6daa43cc8822c2b,Optimization Methods for Personalizing Large Language Models through Retrieval Augmentation,83,-3.549707602339179,4.1692466460268305,0.9439686164288109,2073044451,2295731593,"[""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[5, 6, 10, 11, 11, 14, 17, 21, 23, 26, 28, 41, 46, 53, 59, 61, 68, 74]",12.0,10.0,79
79,dd416e705a68419edb1cb840a6daa43cc8822c2b,Optimization Methods for Personalizing Large Language Models through Retrieval Augmentation,83,-3.549707602339179,4.1692466460268305,0.9439686164288109,2073044451,2295731593,"[""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[5, 6, 10, 11, 11, 14, 17, 21, 23, 26, 28, 41, 46, 53, 59, 61, 68, 74]",12.0,10.0,80
80,2bdccbeffa0bae760f416a72ebe7a3951e230659,Revisiting Reinforcement Learning for LLM Reasoning from A Cross-Domain Perspective,20,0.6000000000000014,4.1,0.9470422535211268,2365396554,2295863002,"[""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[1, 5, 7, 14]",2.0,4.0,81
81,1b05e2243134099efb6d6bde5f2d4944869596a3,LHRS-Bot: Empowering Remote Sensing with VGI-Enhanced Large Multimodal Language Model,91,-8.271428571428567,4.06015037593985,0.9350237982154512,2166353997,2976074,"[""2024-03-01"", ""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[2, 3, 4, 6, 10, 11, 13, 14, 17, 22, 25, 29, 32, 41, 43, 54, 62, 68, 73, 77]",8.0,26.0,82
82,3da5083c580cb001fbbe95973b2486231ff00531,Large Language Model for Vulnerability Detection: Emerging Results and Future Directions,92,-1.597402597402592,4.05974025974026,0.9953527883880825,2148928671,2266756776,"[""2024-02-01"", ""2024-03-01"", ""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[3, 3, 4, 11, 14, 17, 21, 25, 28, 36, 39, 45, 48, 52, 56, 60, 65, 67, 72, 74, 79]",12.0,4.0,83
83,550006bea81e4ccb67743dd1b82a70b86b48d93a,RL-VLM-F: Reinforcement Learning from Vision Language Foundation Model Feedback,89,-6.571428571428565,4.018045112781955,0.9619576142707855,2108111472,3407045,"[""2024-03-01"", ""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[2, 4, 4, 6, 10, 13, 14, 15, 20, 25, 28, 32, 35, 48, 50, 57, 60, 63, 69, 77]",9.0,23.0,84
84,e1770838ec0667cad48729a81764ed9964d6a8e6,LLM-in-the-loop: Leveraging Large Language Model for Thematic Analysis,98,-5.2866666666666555,3.8147826086956536,0.9600511308438293,3400291,1746959,"[""2023-11-01"", ""2023-12-01"", ""2024-01-01"", ""2024-02-01"", ""2024-03-01"", ""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[4, 6, 8, 10, 11, 13, 14, 19, 23, 24, 27, 29, 36, 38, 43, 45, 51, 56, 64, 72, 78, 81, 85, 89]",6.0,27.0,85
85,2d906cda427cb2c4a71069423312e57ba4cd5445,Reinforcement Learning Enhanced LLMs: A Survey,38,-3.018181818181813,3.7818181818181813,0.9546337157987643,2109514219,2285877067,"[""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[1, 1, 4, 8, 9, 12, 18, 25, 28, 34]",11.0,7.0,86
86,3d3f0d7eb69f063e9539dd45df971f007b094734,Large Language Models to Enhance Bayesian Optimization,91,-0.9714285714285642,3.7601503759398494,0.9687304963591267,2121678977,1729969,"[""2024-03-01"", ""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[5, 6, 8, 11, 17, 18, 18, 18, 28, 33, 35, 37, 39, 45, 46, 54, 64, 65, 70, 78]",9.0,71.0,87
87,8d5bc0b0ddca8740e4bec70231b7f0d12ded3d5d,Sycophancy to Subterfuge: Investigating Reward-Tampering in Large Language Models,72,-0.4264705882352916,3.748529411764706,0.9735224820069777,1780754598,146614650,"[""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[3, 6, 7, 11, 16, 19, 20, 23, 25, 28, 34, 39, 47, 51, 54, 60]",13.0,14.0,88
88,8d5bc0b0ddca8740e4bec70231b7f0d12ded3d5d,Sycophancy to Subterfuge: Investigating Reward-Tampering in Large Language Models,72,-0.4264705882352916,3.748529411764706,0.9735224820069777,1780754598,146614650,"[""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[3, 6, 7, 11, 16, 19, 20, 23, 25, 28, 34, 39, 47, 51, 54, 60]",13.0,14.0,89
89,d3f8d5a9c48ee9f338f25f1be5f3adc7fd5dd855,"ReMax: A Simple, Effective, and Efficient Reinforcement Learning Method for Aligning Large Language Models",109,-14.403333333333322,3.734347826086957,0.8325818414515884,25841722,2114939672,"[""2023-11-01"", ""2023-12-01"", ""2024-01-01"", ""2024-02-01"", ""2024-03-01"", ""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[1, 1, 3, 3, 5, 5, 6, 7, 12, 14, 15, 18, 22, 23, 23, 25, 30, 34, 43, 64, 75, 78, 84, 94]",11.0,14.0,90
90,afc5092a4116f27b4c64733c7815cd662bab78f7,Instruct2Act: Mapping Multi-modality Instructions to Robotic Actions with Large Language Model,113,0.35172413793104523,3.733497536945812,0.9940053118606983,2243292807,47893312,"[""2023-06-01"", ""2023-07-01"", ""2023-08-01"", ""2023-09-01"", ""2023-10-01"", ""2023-11-01"", ""2023-12-01"", ""2024-01-01"", ""2024-02-01"", ""2024-03-01"", ""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[1, 2, 5, 6, 12, 19, 23, 28, 30, 34, 40, 42, 48, 52, 55, 58, 62, 68, 72, 73, 74, 78, 83, 85, 88, 94, 95, 98, 101]",13.0,76.0,91
91,b0435af3063195e8ae880489e64ccde64e6d7563,Guiding Large Language Models via Directional Stimulus Prompting,118,-10.926136363636344,3.6323313782991193,0.9868197904661188,2109964198,145026971,"[""2023-03-01"", ""2023-04-01"", ""2023-05-01"", ""2023-06-01"", ""2023-07-01"", ""2023-08-01"", ""2023-09-01"", ""2023-10-01"", ""2023-11-01"", ""2023-12-01"", ""2024-01-01"", ""2024-02-01"", ""2024-03-01"", ""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[0, 1, 1, 3, 4, 6, 7, 10, 14, 16, 20, 24, 33, 35, 36, 41, 48, 51, 51, 55, 63, 68, 69, 71, 74, 79, 87, 90, 91, 97, 103, 104]",16.0,2.0,92
92,4b82d9fbaf5427ff3799de777ffbe3efbf98b81d,Large Language Models (LLMs) Inference Offloading and Resource Allocation in Cloud-Edge Computing: An Active Inference Approach,44,1.3181818181818217,3.6090909090909093,0.9918753933291378,2118918240,2292841223,"[""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[3, 6, 8, 11, 14, 19, 23, 26, 30, 34, 39]",10.0,9.0,93
93,60b0476a97c00e355df28ba35422764a7fbe88e8,In-context Autoencoder for Context Compression in a Large Language Model,105,-6.13492063492063,3.591575091575092,0.9856586657006499,50251691,49807919,"[""2023-08-01"", ""2023-09-01"", ""2023-10-01"", ""2023-11-01"", ""2023-12-01"", ""2024-01-01"", ""2024-02-01"", ""2024-03-01"", ""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[1, 2, 4, 7, 7, 10, 11, 13, 16, 22, 25, 33, 38, 40, 46, 53, 54, 57, 60, 62, 64, 65, 73, 77, 80, 85, 90]",19.0,101.0,94
94,0f82929fcfc9958d442009a7d50e6794f024b7f1,Large Language Models as Generalizable Policies for Embodied Tasks,94,-10.013333333333328,3.570000000000001,0.9456529067813697,1580188581,2238621175,"[""2023-11-01"", ""2023-12-01"", ""2024-01-01"", ""2024-02-01"", ""2024-03-01"", ""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[0, 0, 2, 4, 6, 7, 8, 13, 19, 21, 21, 21, 25, 28, 30, 35, 41, 52, 55, 63, 68, 71, 75, 80]",11.0,12.0,95
95,46566ef7e51987cd101bf2b275c650cb3be21995,Human Alignment of Large Language Models through Online Preference Optimisation,77,11.205263157894743,3.503508771929825,0.97043182658802,2439765,1808897,"[""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[5, 9, 20, 26, 28, 29, 31, 41, 42, 43, 43, 48, 56, 58, 64, 66, 66, 67, 70]",24.0,41.0,96
96,765051eee0fb1394b62555edb86ba1f7a00892fb,Think Twice: Enhancing LLM Reasoning by Scaling Multi-round Test-time Thinking,23,1.3214285714285725,3.4642857142857144,0.9784733777038269,2352756200,2352034310,"[""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[1, 4, 8, 13, 17, 18, 21]",5.0,5.0,97
97,90df9c970aa98aa49bcf79e252ab26b1bb6889c5,Bootstrap Your Own Skills: Learning to Solve New Tasks with Large Language Model Guidance,81,-0.6433333333333243,3.440000000000001,0.9929086155529884,2255687520,2253826001,"[""2023-11-01"", ""2023-12-01"", ""2024-01-01"", ""2024-02-01"", ""2024-03-01"", ""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[3, 4, 6, 8, 13, 14, 16, 19, 26, 31, 36, 38, 43, 47, 50, 53, 55, 57, 60, 64, 68, 70, 75, 78]",8.0,7.0,98
98,ebf35cef5c249d90b40043fffa41f8802c27f132,RL4F: Generating Natural Language Feedback with Reinforcement Learning for Repairing Model Outputs,109,4.393103448275865,3.410344827586207,0.9915321809850955,1754469865,1721168,"[""2023-06-01"", ""2023-07-01"", ""2023-08-01"", ""2023-09-01"", ""2023-10-01"", ""2023-11-01"", ""2023-12-01"", ""2024-01-01"", ""2024-02-01"", ""2024-03-01"", ""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[4, 6, 8, 11, 15, 22, 26, 27, 34, 40, 40, 42, 45, 52, 57, 58, 60, 65, 66, 69, 69, 72, 77, 82, 87, 94, 94, 95, 95]",9.0,29.0,99
99,53106a642a12b05753ebe9ffca62d8efb0670281,Inference-Aware Fine-Tuning for Best-of-N Sampling in Large Language Models,37,0.4000000000000015,3.3999999999999995,0.9871648897629645,1819830,2258552654,"[""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[2, 2, 6, 10, 15, 18, 22, 25, 27, 30]",27.0,5.0,100
100,8e27e73e61d772686c7ff30f8bcafc167058b231,"Survey of Different Large Language Model Architectures: Trends, Benchmarks, and Challenges",34,1.490909090909093,3.290909090909091,0.9817402683021845,2284694862,2238832044,"[""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[3, 4, 6, 11, 14, 20, 23, 24, 28, 30]",5.0,4.0,101
101,0a42291d9543eabe33f6c14278333484071a707c,Offline Reinforcement Learning for LLM Multi-Step Reasoning,35,1.036363636363641,3.2363636363636363,0.9770568644381399,2216204941,2336830631,"[""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[1, 2, 7, 12, 15, 18, 23, 24, 25, 29]",3.0,2.0,102
102,71bd93626ac1b3533f2cdbd82da40ceb2be969b1,MT-R1-Zero: Advancing LLM-based Machine Translation via R1-Zero-like Reinforcement Learning,25,7.33333333333333,3.199999999999999,0.9365853658536585,2266490792,2258784763,"[""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[5, 12, 15, 18, 20, 22]",5.0,8.0,103
103,0659e2a187f43c5fa86632f3003f8b0d13dac329,Strengthening Multimodal Large Language Model with Bootstrapped Preference Optimization,62,-3.552631578947365,3.18421052631579,0.9792525014714538,2066420772,2266465257,"[""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[1, 1, 4, 8, 9, 9, 12, 18, 23, 24, 26, 28, 31, 35, 42, 47, 51, 52, 56]",22.0,10.0,104
104,78b1601c013769294a1927d43e50dfa81d6af75f,LLMs4OL: Large Language Models for Ontology Learning,115,-11.12962962962963,3.0897435897435903,0.9468499773666357,51164027,145044578,"[""2023-08-01"", ""2023-09-01"", ""2023-10-01"", ""2023-11-01"", ""2023-12-01"", ""2024-01-01"", ""2024-02-01"", ""2024-03-01"", ""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[1, 1, 1, 1, 2, 3, 3, 4, 6, 10, 14, 17, 20, 22, 25, 39, 42, 47, 49, 50, 51, 51, 56, 59, 62, 67, 81]",6.0,55.0,105
105,fe13cc3650fd7df8f98d0596bfc13178af82c799,Curiosity-driven Red-teaming for Large Language Models,66,-0.9571428571428501,3.084962406015038,0.9900275126420364,33317877,2257003971,"[""2024-03-01"", ""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[3, 3, 4, 8, 12, 13, 17, 17, 23, 26, 31, 34, 38, 39, 40, 42, 49, 53, 56, 59]",12.0,14.0,106
106,7eece37709dceba5086f48dc43ac1a69d0427486,Joint Knowledge Graph and Large Language Model for Fault Diagnosis and Its Application in Aviation Assembly,69,-1.5686274509803877,3.0784313725490193,0.9396269929763368,2217848572,2242957770,"[""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[5, 5, 7, 9, 9, 10, 12, 18, 22, 22, 26, 29, 33, 38, 41, 51, 55]",5.0,5.0,107
107,02d7673c89a94367edd7a2cf0ea4f5540fba3e42,DeepRetrieval: Hacking Real Search Engines and Retrievers with Large Language Models via Reinforcement Learning,29,1.08333333333333,3.0119047619047614,0.9624400439051528,2348886016,2284641156,"[""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[3, 3, 5, 10, 15, 15, 20, 22]",3.0,6.0,108
108,ecb6a8003d4726cc1e9e9f3c2d8ff6c0627e4e95,Text2Reward: Reward Shaping with Language Models for Reinforcement Learning,83,-14.09846153846154,3.0015384615384613,0.8887650082959785,2057038673,2256865348,"[""2023-10-01"", ""2023-11-01"", ""2023-12-01"", ""2024-01-01"", ""2024-02-01"", ""2024-03-01"", ""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[0, 0, 0, 0, 0, 0, 2, 2, 2, 6, 10, 12, 14, 18, 21, 24, 25, 29, 36, 41, 51, 60, 61, 64, 70]",15.0,8.0,109
109,2d058447fe3fb3384c213de0399c2610ce3cb2b2,FATE-LLM: A Industrial Grade Federated Learning Framework for Large Language Models,71,1.4533333333333425,2.94608695652174,0.9914584407021706,2072650627,2166949653,"[""2023-11-01"", ""2023-12-01"", ""2024-01-01"", ""2024-02-01"", ""2024-03-01"", ""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[2, 3, 8, 8, 11, 13, 17, 24, 29, 31, 33, 34, 38, 40, 44, 46, 47, 51, 55, 58, 62, 64, 64, 66]",9.0,13.0,110
110,dd38755291d108ab86c68d1aac7485921bb8e647,LLM-based Multi-Agent Reinforcement Learning: Current and Future Directions,54,-1.3529411764705794,2.88235294117647,0.966942980836997,2051640686,2241828177,"[""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[2, 2, 6, 8, 10, 15, 16, 17, 17, 19, 25, 28, 32, 38, 41, 45, 48]",8.0,8.0,111
111,d2d16333a4b0dc7e3463b280b9945e5ee6c53396,TrueTeacher: Learning Factual Consistency Evaluation with Large Language Models,91,-1.0275862068965442,2.866502463054187,0.987887735763183,2158816391,1711977,"[""2023-06-01"", ""2023-07-01"", ""2023-08-01"", ""2023-09-01"", ""2023-10-01"", ""2023-11-01"", ""2023-12-01"", ""2024-01-01"", ""2024-02-01"", ""2024-03-01"", ""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[4, 4, 6, 6, 8, 10, 14, 16, 17, 21, 27, 32, 34, 39, 42, 43, 43, 52, 53, 58, 60, 60, 61, 63, 67, 70, 73, 75, 76]",7.0,37.0,112
112,ae03f10729959435ecefc0e90cba4cbe8438a10b,Evaluating Large Language Model Biases in Persona-Steered Generation,54,-2.78431372549019,2.7745098039215677,0.9341568106002286,1998678399,2303850390,"[""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[0, 4, 6, 8, 9, 9, 11, 13, 14, 17, 20, 24, 30, 37, 41, 42, 45]",3.0,2.0,113
113,08e84c939b88fc50aaa74ef76e202e61a1ad940b,StepCoder: Improve Code Generation with Reinforcement Learning from Compiler Feedback,65,-0.9285714285714266,2.760902255639098,0.9556608991654507,2042683163,2067331064,"[""2024-03-01"", ""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[3, 5, 6, 9, 12, 13, 14, 15, 19, 22, 26, 26, 28, 28, 33, 42, 45, 48, 55, 57]",23.0,36.0,114
114,27f0ce04403158b61328716ae4aaab5840c0d123,Batch Prompting: Efficient Inference with Large Language Model APIs,95,-8.397504456327983,2.7426470588235285,0.9858911319780577,,2117900202,"[""2023-02-01"", ""2023-03-01"", ""2023-04-01"", ""2023-05-01"", ""2023-06-01"", ""2023-07-01"", ""2023-08-01"", ""2023-09-01"", ""2023-10-01"", ""2023-11-01"", ""2023-12-01"", ""2024-01-01"", ""2024-02-01"", ""2024-03-01"", ""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[0, 0, 0, 1, 6, 6, 6, 9, 10, 15, 16, 20, 20, 25, 27, 28, 31, 36, 39, 41, 43, 50, 55, 56, 57, 61, 66, 69, 71, 74, 77, 77, 79]",,11.0,115
115,e3116a5d5784392d9190ca35997f65a252291032,Plan-Seq-Learn: Language Model Guided RL for Solving Long Horizon Robotics Tasks,62,5.999999999999999,2.720588235294117,0.9775964504703508,35904540,2256996419,"[""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[8, 9, 12, 15, 18, 21, 22, 23, 26, 27, 30, 33, 40, 43, 43, 49, 53]",13.0,7.0,116
116,3c3237df4b09dc5a21f7bc2b917f72ccbb6cf863,Learning Dynamics of LLM Finetuning,53,-6.591666666666662,2.7035714285714283,0.8015418687057068,2115242507,2262445067,"[""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[1, 1, 1, 3, 4, 4, 4, 6, 6, 7, 20, 25, 29, 32, 42]",9.0,6.0,117
117,eaf9ce4c3e58d8af114afeba0984e6d3b51ed392,VLM-RL: A Unified Vision Language Models and Reinforcement Learning Framework for Safe Autonomous Driving,25,-2.218181818181816,2.648484848484848,0.9184160282398658,2278457018,2238946935,"[""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[1, 1, 2, 3, 4, 11, 16, 19, 19, 21]",8.0,8.0,118
118,13c0f33ccd88607fce4819135e404a988aa8aad4,KICGPT: Large Language Model with Knowledge in Context for Knowledge Graph Completion,60,-2.1571428571428544,2.64812030075188,0.9674978941128756,2273826353,2243335442,"[""2024-03-01"", ""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[4, 4, 4, 6, 8, 10, 11, 13, 15, 18, 22, 27, 30, 30, 32, 39, 44, 47, 47, 49]",2.0,12.0,119
119,7ef10b9b5bbce61573f647774004f95221efe665,AgentsCoDriver: Large Language Model Empowered Collaborative Driving with Lifelong Learning,43,-2.707602339181293,2.638802889576883,0.9701227039288275,2249844970,2256784186,"[""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[1, 2, 3, 4, 7, 10, 13, 13, 15, 18, 20, 26, 32, 35, 38, 38, 40, 40]",9.0,13.0,120
120,aa89c6bf86486e180833037333555e3492b15c8e,MAPoRL: Multi-Agent Post-Co-Training for Collaborative Large Language Models with Reinforcement Learning,24,-1.6666666666666679,2.5833333333333326,0.9346950118104767,2232975456,2347076258,"[""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[0, 1, 4, 4, 8, 9, 14, 19]",3.0,1.0,121
121,fc918d6f8e2523696c34fa1be5aabdb42e9648d2,Do Embodied Agents Dream of Pixelated Sheep?: Embodied Decision Making using Language Guided World Modelling,93,-3.5900178253119366,2.5728609625668444,0.9912824630687956,103596213,145609073,"[""2023-02-01"", ""2023-03-01"", ""2023-04-01"", ""2023-05-01"", ""2023-06-01"", ""2023-07-01"", ""2023-08-01"", ""2023-09-01"", ""2023-10-01"", ""2023-11-01"", ""2023-12-01"", ""2024-01-01"", ""2024-02-01"", ""2024-03-01"", ""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[0, 0, 4, 4, 8, 10, 12, 13, 14, 16, 18, 20, 23, 30, 34, 36, 39, 43, 46, 47, 48, 54, 55, 55, 56, 58, 62, 63, 70, 72, 74, 77, 79]",5.0,18.0,122
122,859d9e9c77ef556fc6257c2a395e9edfcac3b775,"AceGPT, Localizing Large Language Models in Arabic",81,-7.246153846153847,2.543846153846154,0.948952202220095,2243722384,2228993749,"[""2023-10-01"", ""2023-11-01"", ""2023-12-01"", ""2024-01-01"", ""2024-02-01"", ""2024-03-01"", ""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[2, 2, 2, 2, 3, 6, 7, 7, 8, 10, 16, 16, 19, 24, 24, 28, 29, 33, 37, 40, 47, 49, 54, 56, 61]",3.0,6.0,123
123,7b9a44699ead88963586928e3206688f753e2a5b,Reinforcement Learning for Long-Horizon Interactive LLM Agents,23,-0.7500000000000027,2.5357142857142847,0.9614724394430669,2344244384,2343745126,"[""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[0, 1, 3, 8, 11, 11, 13, 18]",1.0,2.0,124
124,7c8a43b48db962a9bf01800663cc81857679905c,Teaching Language Models to Critique via Reinforcement Learning,20,1.166666666666665,2.523809523809523,0.9486659912191827,2275741564,2316451407,"[""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[1, 2, 6, 10, 14, 14, 15, 18]",6.0,2.0,125
125,b2991a4b2ecc9db0fbd9ca738022801b4e5ee001,CogBench: a large language model walks into a psychology lab,50,-2.614285714285708,2.5120300751879703,0.9818885617084536,2215168951,2271334207,"[""2024-03-01"", ""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[1, 2, 2, 5, 7, 11, 11, 13, 17, 21, 21, 22, 24, 28, 31, 35, 39, 42, 46, 47]",7.0,7.0,126
126,3e664adb009dce373129a3563e4b2cb08731bc76,PolyLM: An Open Source Polyglot Large Language Model,69,1.8174603174603206,2.5097680097680106,0.9745896997628736,46252591,2109935759,"[""2023-08-01"", ""2023-09-01"", ""2023-10-01"", ""2023-11-01"", ""2023-12-01"", ""2024-01-01"", ""2024-02-01"", ""2024-03-01"", ""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[0, 3, 6, 6, 11, 11, 12, 16, 23, 27, 31, 33, 35, 37, 39, 44, 46, 49, 49, 52, 53, 53, 57, 58, 58, 60, 61]",10.0,10.0,127
127,9732c864d1d4161fcb106f2961d9a80dd4fffc9a,Dense Reward for Free in Reinforcement Learning from Human Feedback,53,-3.6580086580086504,2.4753246753246754,0.9716132414245622,1768846714,1729969,"[""2024-02-01"", ""2024-03-01"", ""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[1, 1, 2, 4, 6, 9, 10, 13, 15, 17, 20, 20, 22, 25, 28, 31, 40, 42, 44, 46, 47]",8.0,71.0,128
128,e4eaaaf1e435061bb2eed5f6dc187e453c3bb086,Large Language Models Can Automatically Engineer Features for Few-Shot Tabular Learning,43,-6.836257309941519,2.444788441692466,0.9320578339798852,1444699639,2264567300,"[""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[0, 0, 0, 0, 1, 2, 7, 7, 8, 8, 16, 20, 21, 25, 31, 32, 35, 38]",11.0,10.0,129
129,bd05f81167ca3f77460f4a1da3bf5ade9febb15b,Language Instructed Reinforcement Learning for Human-AI Coordination,77,0.3161290322580719,2.405784204671858,0.9785805243937119,3437504,1779671,"[""2023-05-01"", ""2023-06-01"", ""2023-07-01"", ""2023-08-01"", ""2023-09-01"", ""2023-10-01"", ""2023-11-01"", ""2023-12-01"", ""2024-01-01"", ""2024-02-01"", ""2024-03-01"", ""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[0, 0, 3, 5, 5, 10, 14, 16, 18, 21, 26, 30, 30, 38, 40, 43, 43, 46, 46, 47, 49, 51, 52, 54, 54, 59, 60, 64, 65, 67]",15.0,61.0,130
130,d492c004b74dcbec9d5c0732d95bbd3588e30451,Can large language models explore in-context?,46,-4.363157894736841,2.3912280701754396,0.9733367912566931,2280143899,2158559,"[""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[0, 0, 2, 3, 5, 6, 6, 12, 13, 15, 19, 20, 21, 25, 31, 34, 35, 38, 41]",7.0,36.0,131
131,debe978e02b664fb7254b6c7b58a74c09ce897e3,Plug-and-Play Policy Planner for Large Language Model Powered Dialogue Agents,61,-5.479999999999998,2.356956521739131,0.9703667283865519,145843537,2257036129,"[""2023-11-01"", ""2023-12-01"", ""2024-01-01"", ""2024-02-01"", ""2024-03-01"", ""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[0, 1, 2, 2, 4, 5, 7, 10, 12, 15, 16, 18, 21, 21, 22, 26, 32, 34, 36, 42, 44, 45, 50, 54]",27.0,22.0,132
132,1bca0871e893568c5fd346c14c17691f71a8f65a,Value Augmented Sampling for Language Model Alignment and Personalization,39,-0.5686274509803874,2.3504901960784306,0.9855977794924554,2301077050,2257003971,"[""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[1, 2, 4, 6, 7, 13, 13, 15, 15, 20, 24, 27, 29, 31, 33, 35, 35]",2.0,14.0,133
133,462041e29f2e4e8d78b3214ee1a286865bc68721,ChiMed-GPT: A Chinese Medical Large Language Model with Full Training Regime and Better Alignment to Human Preferences,56,-6.7717391304347805,2.2994071146245063,0.9348295290538123,151472012,2266360133,"[""2023-12-01"", ""2024-01-01"", ""2024-02-01"", ""2024-03-01"", ""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[1, 1, 2, 3, 3, 3, 3, 7, 8, 9, 11, 15, 17, 20, 23, 26, 27, 29, 38, 41, 45, 47, 47]",13.0,4.0,134
134,63a1617af179ee8b5b096b3038913a19166168d4,Open-RAG: Enhanced Retrieval-Augmented Reasoning with Open-Source Large Language Models,32,0.7820512820512793,2.297202797202797,0.9814212015360818,2232783785,3405393,"[""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[3, 3, 5, 5, 10, 12, 15, 16, 20, 22, 24, 26]",4.0,15.0,135
135,6a4719871c5d51ad2cd140561652500df06409bd,Algorithm Evolution Using Large Language Model,57,-2.6195652173913038,2.2855731225296445,0.9812150336953029,2256759231,2248220773,"[""2023-12-01"", ""2024-01-01"", ""2024-02-01"", ""2024-03-01"", ""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[0, 0, 2, 4, 7, 8, 13, 16, 16, 17, 17, 24, 24, 24, 26, 29, 32, 34, 38, 43, 44, 48, 52]",12.0,12.0,136
136,19f57c712d0a5dd47fb499aef9f76374dd5acea9,A Large Language Model Enhanced Conversational Recommender System,58,-3.6239316239316186,2.2714529914529917,0.9821872448173588,2047904135,143770118,"[""2023-09-01"", ""2023-10-01"", ""2023-11-01"", ""2023-12-01"", ""2024-01-01"", ""2024-02-01"", ""2024-03-01"", ""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[2, 2, 3, 4, 5, 7, 10, 11, 12, 15, 17, 21, 22, 22, 27, 29, 29, 33, 37, 39, 42, 45, 49, 51, 53, 57]",13.0,30.0,137
137,650b1a96677525a52d747ca10dc9f914bec32d35,ADO-LLM: Analog Design Bayesian Optimization with In-Context Learning of Large Language Models,34,-6.154411764705882,2.1455882352941176,0.8548662188889893,2261094546,2261268671,"[""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[0, 0, 0, 1, 1, 3, 3, 4, 4, 7, 11, 21, 23, 23, 27, 31]",3.0,2.0,138
138,e4148c7b73aeb7602070d605df13473c7748bc97,Uncovering Overfitting in Large Language Model Editing,20,-1.1666666666666687,2.090909090909091,0.9239140170174653,48985110,1721165,"[""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[1, 1, 1, 2, 5, 11, 12, 17, 18, 18, 18, 20]",13.0,38.0,139
139,c226a4acb42912054d498bcf771023b0ba2da001,Language Model Self-improvement by Reinforcement Learning Contemplation,66,-7.351724137931024,2.0694581280788173,0.9669625529685975,1432234123,2152850415,"[""2023-06-01"", ""2023-07-01"", ""2023-08-01"", ""2023-09-01"", ""2023-10-01"", ""2023-11-01"", ""2023-12-01"", ""2024-01-01"", ""2024-02-01"", ""2024-03-01"", ""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[0, 0, 0, 2, 3, 3, 3, 3, 4, 8, 9, 12, 16, 20, 22, 22, 23, 26, 28, 29, 31, 37, 39, 39, 43, 49, 50, 51, 55]",8.0,14.0,140
140,1e672bf4d38a93c4c140ee208216425444368fa6,LMRL Gym: Benchmarks for Multi-Turn Reinforcement Learning with Language Models,52,-2.402173913043476,2.0523715415019765,0.9611010558472621,2007538346,2268967207,"[""2023-12-01"", ""2024-01-01"", ""2024-02-01"", ""2024-03-01"", ""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[1, 2, 2, 4, 6, 8, 10, 15, 15, 15, 15, 18, 19, 19, 20, 27, 30, 31, 35, 40, 43, 44, 45]",5.0,9.0,141
141,4ed96712afa0d0e82cddb3d669d4e9f60195aecb,CheatAgent: Attacking LLM-Empowered Recommender Systems via LLM Agent,30,0.34285714285714397,2.0461538461538464,0.9727029407968937,2301015154,2266407320,"[""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[2, 3, 5, 7, 7, 8, 10, 14, 18, 20, 22, 23, 26, 26]",6.0,9.0,142
142,450ce5f335d2b1224ef36e680e94ee00d2f12a6c,Reinforcement Learning for Optimizing RAG for Domain Chatbots,41,-2.5584415584415545,1.9701298701298702,0.9657838191722413,2351058841,35108744,"[""2024-02-01"", ""2024-03-01"", ""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[1, 3, 3, 3, 4, 5, 9, 10, 11, 16, 17, 18, 19, 20, 21, 25, 29, 33, 35, 38, 40]",2.0,10.0,143
143,58e2acdd805d9cc48c7fdde0c9c09280f9f6c4e0,RewriteLM: An Instruction-Tuned Large Language Model for Text Rewriting,65,-5.172413793103442,1.9532019704433494,0.9842793658028389,145142456,2218226973,"[""2023-06-01"", ""2023-07-01"", ""2023-08-01"", ""2023-09-01"", ""2023-10-01"", ""2023-11-01"", ""2023-12-01"", ""2024-01-01"", ""2024-02-01"", ""2024-03-01"", ""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[0, 0, 0, 1, 3, 5, 6, 7, 8, 11, 13, 16, 17, 19, 21, 21, 23, 29, 31, 32, 32, 33, 36, 40, 43, 45, 47, 50, 54]",15.0,8.0,144
144,a497bace44792275c78e52fc158c81e3c15e93ef,Learning to Generate Better Than Your LLM,52,-4.406403940886701,1.942802408319649,0.9775832729324695,2157681314,144426657,"[""2023-07-01"", ""2023-08-01"", ""2023-09-01"", ""2023-10-01"", ""2023-11-01"", ""2023-12-01"", ""2024-01-01"", ""2024-02-01"", ""2024-03-01"", ""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[0, 1, 2, 2, 4, 4, 4, 5, 8, 8, 12, 15, 20, 21, 24, 25, 30, 32, 32, 32, 33, 36, 38, 41, 44, 46, 46, 46]",4.0,36.0,145
145,7d6168fbd3ed72f9098573007f4b8c2ec9e576b9,Training Large Language Models for Reasoning through Reverse Curriculum Reinforcement Learning,43,-4.685714285714282,1.8984962406015036,0.9317025922759125,2190751523,2257129989,"[""2024-03-01"", ""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[0, 1, 1, 2, 4, 4, 4, 6, 8, 11, 11, 12, 14, 17, 20, 25, 27, 30, 33, 37]",13.0,23.0,146
146,d3767fa551f15ca6967db1f55562cee902c747ab,Revisiting Catastrophic Forgetting in Large Language Model Tuning,35,-2.7500000000000013,1.875,0.927003053657118,2305524549,2255502438,"[""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[2, 2, 2, 2, 3, 3, 6, 7, 11, 13, 16, 19, 21, 21, 23, 30]",1.0,16.0,147
147,d5c358380b2b2fb9c0e8be6212158e0a01dacb16,TCRA-LLM: Token Compression Retrieval Augmented Large Language Model for Inference Cost Reduction,42,-2.7933333333333294,1.8660869565217395,0.9840979542993903,2261392830,2261689267,"[""2023-11-01"", ""2023-12-01"", ""2024-01-01"", ""2024-02-01"", ""2024-03-01"", ""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[1, 1, 1, 1, 3, 5, 7, 7, 10, 14, 16, 17, 22, 24, 25, 26, 27, 30, 31, 33, 35, 35, 38, 39]",1.0,4.0,148
148,8a16740aec48eb80bf0e7cff0e83455181bb8759,DP-OPT: Make Large Language Model Your Privacy-Preserving Prompt Engineer,50,-0.4239130434782566,1.864624505928854,0.9619228358708924,2110805917,2237946662,"[""2023-12-01"", ""2024-01-01"", ""2024-02-01"", ""2024-03-01"", ""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[4, 4, 4, 6, 8, 9, 10, 12, 13, 13, 15, 21, 21, 22, 22, 23, 27, 31, 33, 38, 40, 42, 44]",12.0,5.0,149
149,aee47d4f45d5c02f79fff62ce4147f0d382cd87e,Aligning Large Language Models with Human Preferences through Representation Engineering,58,3.332015810276678,1.825522303783173,0.9563950102302705,2257377140,2257129987,"[""2024-01-01"", ""2024-02-01"", ""2024-03-01"", ""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[3, 4, 10, 10, 10, 12, 18, 18, 18, 20, 22, 22, 22, 23, 27, 27, 28, 36, 37, 39, 42, 47]",5.0,8.0,150
150,95a52dd5adf6eb8d918cdfbf6189aab4eaa8e607,FLAME: Factuality-Aware Alignment for Large Language Models,34,0.0784313725490252,1.8137254901960782,0.9753213074577527,122045993,2292024725,"[""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[2, 3, 4, 5, 6, 11, 11, 12, 12, 15, 18, 18, 21, 23, 27, 29, 31]",17.0,5.0,151
151,a72955288e6468b8342eff6f8f0281ceaefc526a,SelfIE: Self-Interpretation of Large Language Model Embeddings,40,-0.7368421052631576,1.8070175438596494,0.9781847016301541,2259331717,7700460,"[""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[2, 2, 2, 6, 6, 7, 7, 11, 15, 16, 16, 20, 20, 20, 25, 28, 28, 31, 33]",3.0,14.0,152
152,49f302e9a76eb39c88fcd861bdd0d954bd3d76b0,Large Language Model for Multi-objective Evolutionary Optimization,45,2.4766666666666737,1.7773913043478262,0.962168481859269,2256759231,2248220773,"[""2023-11-01"", ""2023-12-01"", ""2024-01-01"", ""2024-02-01"", ""2024-03-01"", ""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[2, 3, 4, 7, 8, 11, 12, 14, 18, 19, 19, 20, 29, 30, 32, 32, 34, 34, 34, 36, 37, 38, 38, 39]",12.0,12.0,153
153,31968a970f14beab3cbadf9f6ad45c1a51f4ea95,Benchmarking Hallucination in Large Language Models Based on Unanswerable Math Word Problem,33,-2.6105263157894725,1.7578947368421056,0.9703897007654837,2290246362,2303431895,"[""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[0, 1, 1, 2, 3, 3, 5, 12, 13, 14, 15, 16, 17, 18, 21, 25, 27, 28, 30]",2.0,2.0,154
154,57451ce18f3035fcadf64db38420434f9299b7f3,Optimizing Autonomous Driving for Safety: A Human-Centric Approach with LLM-Enhanced RLHF,27,-1.808823529411765,1.7411764705882353,0.9396321518580085,2305569663,2305484057,"[""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[0, 0, 0, 1, 2, 6, 10, 11, 13, 18, 18, 19, 20, 20, 21, 21]",4.0,3.0,155
155,59084df7203c6be33838ba3e3854eb9bda053ed2,Improving Large Language Models via Fine-grained Reinforcement Learning with Minimum Editing Constraint,37,2.389610389610393,1.675324675324675,0.9865776586788717,2256558402,2274218622,"[""2024-02-01"", ""2024-03-01"", ""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[2, 5, 6, 6, 7, 11, 12, 14, 15, 19, 20, 21, 23, 25, 27, 29, 31, 31, 32, 33, 33]",11.0,15.0,156
156,3b5e7f456043fa96dc4673dc11156834fd9a985e,Learning diverse attacks on large language models for robust red-teaming and safety tuning,35,-0.7647058823529385,1.6691176470588234,0.9631828830625062,1472875852,1383135665,"[""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[0, 2, 3, 4, 5, 9, 10, 10, 11, 14, 16, 16, 17, 20, 22, 24, 31]",13.0,17.0,157
157,6b4da2023c3a11aea6e3ccb9ab13e594833c47eb,Self-Refined Large Language Model as Automated Reward Function Designer for Deep Reinforcement Learning in Robotics,37,-3.8430769230769215,1.6669230769230767,0.9887397649539896,3427937,,"[""2023-10-01"", ""2023-11-01"", ""2023-12-01"", ""2024-01-01"", ""2024-02-01"", ""2024-03-01"", ""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[0, 0, 0, 0, 1, 3, 6, 7, 9, 10, 12, 13, 16, 18, 19, 22, 23, 24, 26, 27, 31, 33, 34, 34, 36]",10.0,,158
158,21029921a9a0e13efc9ab7b5c98a3412a9be7ab4,Large language model applications for evaluation: Opportunities and ethical implications,55,-3.006896551724133,1.6581280788177337,0.9350787103291522,122315957,2265311713,"[""2023-06-01"", ""2023-07-01"", ""2023-08-01"", ""2023-09-01"", ""2023-10-01"", ""2023-11-01"", ""2023-12-01"", ""2024-01-01"", ""2024-02-01"", ""2024-03-01"", ""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[5, 5, 5, 5, 5, 5, 5, 5, 6, 7, 11, 12, 13, 16, 19, 20, 21, 24, 27, 28, 29, 30, 30, 34, 35, 41, 44, 48, 51]",1.0,1.0,159
159,eff0410f7d5d78ea6874596a0a77b184d03ecca5,On the Algorithmic Bias of Aligning Large Language Models with RLHF: Preference Collapse and Matching Regularization,31,-2.5686274509803892,1.6372549019607838,0.8664678286264641,2186871609,2288099064,"[""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[1, 1, 3, 4, 4, 6, 6, 6, 6, 7, 9, 11, 18, 21, 22, 26, 28]",7.0,6.0,160
160,a70f0f9b9b9dc7d5caadcb23a551ea4213727548,Large Language Model-based Human-Agent Collaboration for Complex Task Solving,32,-2.4999999999999956,1.6315789473684212,0.9748145142592163,2163940136,2266834033,"[""2024-03-01"", ""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[0, 0, 2, 3, 4, 6, 7, 7, 9, 11, 12, 13, 16, 17, 19, 24, 26, 26, 28, 30]",3.0,7.0,161
161,f648d5bff46b180c633c812c71aa1cfafd7576dc,Privacy-Preserving Instructions for Aligning Large Language Models,32,-3.442857142857141,1.6045112781954889,0.9547253701955088,2282913846,2258560444,"[""2024-03-01"", ""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[0, 0, 1, 1, 3, 5, 5, 5, 9, 11, 11, 11, 13, 15, 17, 21, 25, 27, 27, 29]",2.0,3.0,162
162,1e34c51b52002796fea6f523b9f794f1d75d9ba8,On Reinforcement Learning and Distribution Matching for Fine-Tuning Language Models with no Catastrophic Forgetting,69,-7.905923344947734,1.55383275261324,0.9453491663663994,30023177,2954698,"[""2022-06-01"", ""2022-07-01"", ""2022-08-01"", ""2022-09-01"", ""2022-10-01"", ""2022-11-01"", ""2022-12-01"", ""2023-01-01"", ""2023-02-01"", ""2023-03-01"", ""2023-04-01"", ""2023-05-01"", ""2023-06-01"", ""2023-07-01"", ""2023-08-01"", ""2023-09-01"", ""2023-10-01"", ""2023-11-01"", ""2023-12-01"", ""2024-01-01"", ""2024-02-01"", ""2024-03-01"", ""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[2, 2, 2, 2, 2, 2, 2, 2, 2, 6, 7, 8, 10, 11, 12, 12, 13, 13, 14, 15, 16, 20, 21, 23, 25, 28, 30, 31, 34, 37, 38, 39, 41, 44, 47, 50, 54, 55, 58, 59, 61]",12.0,24.0,163
163,b6b6e59f3bfdda9d4a4dfe56c46b30706fd18cf3,Enhance Reasoning for Large Language Models in the Game Werewolf,29,0.7428571428571471,1.44812030075188,0.9869354915952301,2175444207,2268469,"[""2024-03-01"", ""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[1, 2, 5, 6, 7, 7, 9, 9, 11, 13, 15, 17, 19, 20, 21, 23, 26, 26, 26, 27]",6.0,13.0,164
164,128e6eb7b0c1caf02dc1f0c7246954f6bd1b84dd,Active Preference Learning for Large Language Models,40,-1.6571428571428537,1.442857142857143,0.9090393174900218,2283933368,2282542157,"[""2024-03-01"", ""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[3, 3, 3, 3, 4, 4, 5, 6, 9, 10, 11, 11, 12, 15, 16, 20, 24, 25, 25, 32]",1.0,3.0,165
165,cc1446a3ccb51bcf8f68827fe05c6841a963cfa3,AutoTutor meets Large Language Models: A Language Model Tutor with Rich Pedagogy and Guardrails,33,-3.8142857142857114,1.4383458646616543,0.9432503647793166,2105636395,2790926,"[""2024-03-01"", ""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[0, 0, 1, 1, 1, 3, 3, 5, 6, 6, 8, 9, 12, 13, 17, 19, 22, 22, 23, 26]",7.0,36.0,166
166,3c7bcbc6c978f39a5db2d687906e7c7a8014102d,LLM-Empowered State Representation for Reinforcement Learning,21,-3.433333333333332,1.4142857142857144,0.8540928368093882,2223444420,2305263249,"[""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[0, 0, 0, 2, 2, 2, 2, 2, 4, 6, 12, 15, 15, 16, 19]",5.0,4.0,167
167,087699924e3dc468a486e0763f1cc097824a60d2,A Critical Evaluation of AI Feedback for Aligning Large Language Models,34,2.457142857142859,1.3571428571428572,0.9289154211606906,50465276,2836353,"[""2024-03-01"", ""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[0, 0, 3, 3, 12, 12, 14, 14, 15, 16, 17, 17, 20, 21, 21, 22, 23, 25, 25, 27]",21.0,30.0,168
168,911f28279f8f80f1520181ecc4e839c54408a68c,Offline Actor-Critic Reinforcement Learning Scales to Large Models,31,-3.299999999999997,1.3421052631578947,0.9207340384860456,2060551,2268407692,"[""2024-03-01"", ""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[0, 1, 1, 1, 3, 3, 3, 5, 5, 7, 8, 8, 11, 11, 14, 17, 19, 21, 25, 26]",41.0,7.0,169
169,ff59b0fe9faa8835c18c9a017de1c6d6fcd64408,A Multi-Expert Large Language Model Architecture for Verilog Code Generation,23,-3.3567251461988312,1.3230134158926725,0.8966710991875975,1605994999,2282247356,"[""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[1, 1, 1, 1, 1, 1, 2, 2, 4, 6, 7, 12, 14, 14, 17, 18, 19, 21]",4.0,4.0,170
170,c27c5a272d1112c6c0ce64ff7892752f7ea4b139,BAT: Learning to Reason about Spatial Sounds with Large Language Models,33,-3.8142857142857114,1.31203007518797,0.8870219988388701,6950445,2307105347,"[""2024-03-01"", ""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[0, 0, 0, 0, 1, 3, 3, 5, 7, 7, 7, 8, 8, 9, 11, 14, 18, 21, 24, 27]",10.0,15.0,171
171,c27c5a272d1112c6c0ce64ff7892752f7ea4b139,BAT: Learning to Reason about Spatial Sounds with Large Language Models,33,-3.8142857142857114,1.31203007518797,0.8870219988388701,6950445,2307105347,"[""2024-03-01"", ""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[0, 0, 0, 0, 1, 3, 3, 5, 7, 7, 7, 8, 8, 9, 11, 14, 18, 21, 24, 27]",10.0,15.0,172
172,8115ffbbadd1055424d18369dba66ce32a572800,ChatGLM-RLHF: Practices of Aligning Large Language Models with Human Feedback,25,0.9578947368421067,1.3087719298245617,0.9650678042520723,2068251467,2243402027,"[""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[1, 2, 2, 4, 5, 6, 9, 12, 12, 14, 15, 17, 19, 19, 20, 21, 21, 21, 22]",13.0,32.0,173
173,28cbd1f2a472ba9a0330c97e7e6820b29883a69e,True Knowledge Comes from Practice: Aligning LLMs with Embodied Environments via Reinforcement Learning,30,-0.9696969696969681,1.292207792207792,0.9883119259949421,2281324573,2277251460,"[""2024-02-01"", ""2024-03-01"", ""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[0, 1, 1, 3, 4, 5, 7, 7, 9, 12, 12, 14, 14, 15, 17, 17, 19, 22, 22, 23, 27]",4.0,7.0,174
174,7f96bb27a8fca35b1f7d02ee319a64be04114809,LLM-Assisted Light: Leveraging Large Language Model Capabilities for Human-Mimetic Traffic Signal Control in Complex Urban Environments,23,-1.531578947368421,1.2754385964912285,0.9549887973402718,2265927745,2291077490,"[""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[1, 1, 2, 2, 4, 4, 5, 6, 8, 8, 9, 10, 14, 14, 18, 20, 21, 21, 21]",5.0,3.0,175
175,9c9ca3a8320c0babd9fc331cc376ffff32fe1f67,Online Merging Optimizers for Boosting Rewards and Mitigating Tax in Alignment,25,5.235294117647059,1.2720588235294115,0.8896143785668992,2257001403,2257314035,"[""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[0, 4, 7, 10, 12, 14, 15, 16, 16, 19, 20, 20, 21, 22, 22, 22, 22]",13.0,8.0,176
176,dd5ef6ceed4e77eb2702b40ba4afece05c1b0af8,PICLe: Eliciting Diverse Behaviors from Large Language Models with Persona In-Context Learning,24,3.8235294117647074,1.2647058823529411,0.9814225053078556,2162122419,2300129169,"[""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[4, 6, 6, 7, 8, 12, 12, 12, 12, 15, 16, 19, 19, 20, 22, 23, 24]",8.0,3.0,177
177,a2f44031dfa55f6da176955bcc37aac726de3a00,Unleashing the Power of Pre-trained Language Models for Offline Reinforcement Learning,29,-2.9433333333333302,1.2595652173913043,0.9704897098205036,2253399644,2255379295,"[""2023-11-01"", ""2023-12-01"", ""2024-01-01"", ""2024-02-01"", ""2024-03-01"", ""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[0, 0, 0, 0, 0, 1, 3, 3, 7, 9, 10, 11, 15, 15, 16, 16, 17, 17, 18, 21, 24, 24, 25, 25]",3.0,11.0,178
178,c3b0da01017870729a7a83b94e7787e5105cbc32,Learning to Rewrite Prompts for Personalized Text Generation,35,-6.25230769230769,1.2576923076923077,0.8307183290822034,2249775049,2240516450,"[""2023-10-01"", ""2023-11-01"", ""2023-12-01"", ""2024-01-01"", ""2024-02-01"", ""2024-03-01"", ""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[0, 0, 0, 0, 1, 1, 1, 1, 1, 3, 3, 3, 4, 5, 6, 7, 9, 11, 15, 19, 23, 24, 24, 29, 31]",5.0,9.0,179
179,82a8b7956661a077d41f58bee59aadd7ff9c79a0,AGILE: A Novel Reinforcement Learning Framework of LLM Agents,23,-3.7254901960784275,1.2524509803921564,0.8538723643593366,2302773746,2267425733,"[""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[0, 0, 1, 1, 1, 1, 1, 2, 3, 4, 7, 9, 11, 13, 14, 17, 22]",2.0,4.0,180
180,dc7f6c4b42c4c639d62c8de5a3d228d155bf84fe,Inverse-RLignment: Inverse Reinforcement Learning from Demonstrations for LLM Alignment,23,0.3529411764705891,1.2058823529411762,0.9726133076181293,2257404641,1729969,"[""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[1, 3, 3, 4, 5, 6, 7, 8, 8, 9, 13, 14, 16, 17, 18, 19, 19]",6.0,71.0,181
181,76eb8409fccfe15a4d7ef8a8bb5ad0eddd097bd4,The Inadequacy of Reinforcement Learning From Human FeedbackRadicalizing Large Language Models via Semantic Vulnerabilities,31,8.733333333333336,1.1714285714285715,0.9828493471058273,11430146,2070517,"[""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[8, 9, 11, 13, 14, 14, 16, 18, 19, 19, 21, 22, 22, 23, 25]",17.0,29.0,182
182,8db1d30ac06dde4bd19d0a86241137ac2be21552,LLM-Powered Code Vulnerability Repair with Reinforcement Learning and Semantic Reward,27,-0.5367965367965359,1.12987012987013,0.9120229421546024,2215168083,71756373,"[""2024-02-01"", ""2024-03-01"", ""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[2, 2, 2, 3, 5, 5, 6, 7, 8, 10, 10, 10, 10, 11, 11, 13, 19, 22, 23, 23, 24]",4.0,15.0,183
183,fa8fa745f58d362925dd44f02750bab1b30a1189,RL-GPT: Integrating Reinforcement Learning and Code-as-policy,22,-1.6571428571428561,1.1270676691729327,0.9567214655927434,2288676140,2273012826,"[""2024-03-01"", ""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[1, 1, 2, 2, 2, 2, 3, 4, 8, 9, 9, 9, 10, 13, 14, 16, 17, 19, 20, 20]",4.0,10.0,184
184,f9db375824ca667897229f570ceb699ab05f1483,Large Language Models are Learnable Planners for Long-Term Recommendation,25,-0.7857142857142839,1.098496240601504,0.9731993254010048,2153422494,2275173839,"[""2024-03-01"", ""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[1, 1, 2, 2, 3, 3, 6, 7, 9, 9, 9, 10, 13, 13, 13, 15, 16, 19, 21, 21]",8.0,7.0,185
185,047e3812854a86b2a2e113219fa956eda860ce24,Introspective Tips: Large Language Model for In-Context Decision Making,33,0.20689655172413962,1.066502463054187,0.9590975871269787,2108438312,2109581369,"[""2023-06-01"", ""2023-07-01"", ""2023-08-01"", ""2023-09-01"", ""2023-10-01"", ""2023-11-01"", ""2023-12-01"", ""2024-01-01"", ""2024-02-01"", ""2024-03-01"", ""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[0, 0, 1, 2, 3, 5, 5, 6, 10, 11, 12, 13, 15, 18, 19, 19, 19, 19, 19, 20, 20, 20, 20, 22, 27, 28, 28, 28, 30]",7.0,22.0,186
186,5609bde8e191eb61a304047d2434868e243df5be,LLMLight: Large Language Models as Traffic Signal Control Agents,28,-4.296442687747035,1.054206662902315,0.6980121299940305,2175278345,2247992230,"[""2024-01-01"", ""2024-02-01"", ""2024-03-01"", ""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[0, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 5, 7, 9, 14, 18, 21, 24, 26]",4.0,8.0,187
187,3714ed902e79dad5dcc93c5d033c8222d044f3c8,Reinforcement Learning from Automatic Feedback for High-Quality Unit Test Generation,26,-1.456666666666665,1.0360869565217394,0.9584918834297064,2108813860,2061625488,"[""2023-11-01"", ""2023-12-01"", ""2024-01-01"", ""2024-02-01"", ""2024-03-01"", ""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[2, 2, 2, 2, 2, 3, 3, 4, 6, 7, 9, 9, 9, 11, 12, 13, 14, 15, 17, 19, 22, 22, 23, 23]",6.0,13.0,188
188,60e6e3767c36bf9e16b58b7221c5712b4d3d5293,Large Language Models Are Semi-Parametric Reinforcement Learning Agents,31,-3.0147783251231512,1.0328407224958946,0.9735811820058714,2118333,1736727,"[""2023-07-01"", ""2023-08-01"", ""2023-09-01"", ""2023-10-01"", ""2023-11-01"", ""2023-12-01"", ""2024-01-01"", ""2024-02-01"", ""2024-03-01"", ""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[0, 0, 1, 1, 2, 2, 2, 3, 4, 4, 6, 7, 8, 10, 11, 11, 14, 14, 15, 15, 17, 19, 20, 21, 23, 23, 25, 28]",12.0,51.0,189
189,f7a30e15759805555950c3341b54e95832d5a440,Learning Mathematics with Large Language Models: A Comparative Study with Computer Algebra Systems and Other Tools,26,-2.2466666666666657,1.0069565217391305,0.9439198479551374,2260098123,2260065898,"[""2023-11-01"", ""2023-12-01"", ""2024-01-01"", ""2024-02-01"", ""2024-03-01"", ""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[0, 0, 2, 3, 3, 3, 3, 3, 3, 6, 6, 6, 7, 9, 10, 13, 13, 16, 17, 19, 19, 20, 21, 22]",2.0,2.0,190
190,5f5613630ad62a8db6374ad2ab4a15fb51152a2d,Long-horizon Locomotion and Manipulation on a Quadrupedal Robot with Large Language Models,20,3.0643274853801183,0.959752321981424,0.9595230452680984,2212795288,2293552963,"[""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[1, 3, 4, 7, 7, 9, 10, 11, 12, 12, 12, 15, 15, 15, 15, 17, 18, 19]",3.0,2.0,191
191,e10d2f218692f6b938f7e7e1ba355db9cdc7816b,Enabling Intelligent Interactions between an Agent and an LLM: A Reinforcement Learning Approach,29,-0.2586206896551727,0.9318555008210181,0.9696699859015943,2145118367,47655556,"[""2023-07-01"", ""2023-08-01"", ""2023-09-01"", ""2023-10-01"", ""2023-11-01"", ""2023-12-01"", ""2024-01-01"", ""2024-02-01"", ""2024-03-01"", ""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[0, 0, 1, 1, 3, 4, 6, 7, 8, 9, 9, 9, 10, 15, 15, 15, 16, 16, 16, 16, 16, 18, 19, 19, 21, 25, 25, 26]",4.0,85.0,192
192,9e0da24b96eb4f3f77ccdfc485a4d7d7d21a4585,Large Language Model as a Policy Teacher for Training Reinforcement Learning Agents,23,-1.456521739130434,0.922924901185771,0.8897088820352148,,2267730082,"[""2023-12-01"", ""2024-01-01"", ""2024-02-01"", ""2024-03-01"", ""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[1, 1, 2, 2, 3, 4, 4, 4, 5, 5, 5, 9, 9, 9, 10, 10, 10, 10, 15, 18, 19, 22, 23]",,1.0,193
193,e495d6ca8b57d3056ea6859d0bf134ae44dbecef,Real-Time Optimal Power Flow With Linguistic Stipulations: Integrating GPT-Agent and Deep Reinforcement Learning,20,-1.171428571428571,0.8917293233082707,0.8581556129857262,2239428918,2118040469,"[""2024-03-01"", ""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[1, 2, 2, 2, 3, 4, 4, 4, 4, 5, 5, 6, 7, 7, 9, 13, 15, 17, 18, 18]",3.0,15.0,194
194,f782d5f569eaa4eb2d66e0cb95bdba0941dbb8b0,"Reinforcement Learning in the Era of LLMs: What is Essential? What is needed? An RL Perspective on RLHF, Prompting, and Beyond",25,3.0933333333333377,0.8034782608695652,0.9803000612369871,2257089965,2257089965,"[""2023-11-01"", ""2023-12-01"", ""2024-01-01"", ""2024-02-01"", ""2024-03-01"", ""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[4, 5, 5, 5, 7, 7, 7, 8, 10, 10, 10, 10, 13, 13, 15, 15, 16, 17, 17, 20, 20, 20, 20, 22]",1.0,1.0,195
195,f782d5f569eaa4eb2d66e0cb95bdba0941dbb8b0,"Reinforcement Learning in the Era of LLMs: What is Essential? What is needed? An RL Perspective on RLHF, Prompting, and Beyond",25,3.0933333333333377,0.8034782608695652,0.9803000612369871,2257089965,2257089965,"[""2023-11-01"", ""2023-12-01"", ""2024-01-01"", ""2024-02-01"", ""2024-03-01"", ""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[4, 5, 5, 5, 7, 7, 7, 8, 10, 10, 10, 10, 13, 13, 15, 15, 16, 17, 17, 20, 20, 20, 20, 22]",1.0,1.0,196
196,0fe8f2f55046ad0b8d6337f57a78466790923264,Outcome-based Exploration for LLM Reasoning,25,0.0,0.0,0.0,2379687376,2237802765,"[""2025-10-01""]",[11],1.0,10.0,197
197,6c6189a5fbda8ddf84ef23e5a43f7c85e2120b67,A Survey of Reinforcement Learning for Large Reasoning Models,33,0.0,0.0,0.0,2153281320,2310664569,"[""2025-10-01""]",[17],17.0,5.0,198
198,ad74032137b4129b54c5c06be208843d73792e7f,RL's Razor: Why Online Reinforcement Learning Forgets Less,26,0.0,0.0,0.0,2164041844,2329183817,"[""2025-10-01""]",[17],10.0,4.0,199
