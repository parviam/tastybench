rank,paperId,title,a,b,R2,total_citations,citation_dates,citation_counts
1,cd27f45bc760447fb4de3209e2381ea3493bbd57,ReST-MCTS*: LLM Self-Training via Process Reward Guided Tree Search,20.70626942147712,0.17650075635589613,0.9410348747603713,291,"[""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[8, 9, 9, 14, 26, 30, 40, 51, 87, 118, 138, 181, 208, 222, 235, 258]"
2,da0d382c7fa981ba185ca633868442b75cb76de6,ELLA: Equip Diffusion Models with LLM for Enhanced Semantic Alignment,7.479328606756664,0.17226648425049818,0.980531302092221,173,"[""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[0, 3, 5, 9, 10, 11, 14, 22, 26, 38, 40, 48, 60, 71, 97, 114, 123, 135, 155]"
3,f32bcc2155997110a7905da050df4c8404867b24,Improve Mathematical Reasoning in Language Models by Automated Process Supervision,24.381456587862527,0.16311567058569998,0.9347849881182808,273,"[""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[5, 7, 9, 14, 36, 40, 52, 60, 94, 131, 145, 183, 203, 215, 228, 248]"
4,a3d2c1c932da66f48af673bcb860ba0b8fb335d1,Making Reasoning Matter: Measuring and Improving Faithfulness of Chain-of-Thought Reasoning,2.3647669451675513,0.15971938300455,0.9860535028927719,62,"[""2024-03-01"", ""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[3, 3, 3, 5, 6, 7, 7, 7, 9, 9, 11, 13, 18, 19, 21, 28, 28, 33, 40, 53]"
5,c44471e846846bde281779405a3b5c132fd60b00,"Survey on Large Language Model-Enhanced Reinforcement Learning: Concept, Taxonomy, and Methods",6.331306194364252,0.15911768958347963,0.9809417311503851,115,"[""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[2, 2, 4, 7, 12, 13, 16, 23, 24, 26, 26, 32, 44, 48, 66, 78, 85, 94, 103]"
6,1243ccec1a27112bd37d1891b152ad68be8e4777,"WorldCoder, a Model-Based LLM Agent: Building World Models by Writing Code and Interacting with the Environment",2.725974626032615,0.15884945367213676,0.9805172512734572,58,"[""2024-03-01"", ""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[0, 0, 0, 5, 6, 7, 7, 7, 9, 10, 12, 14, 17, 23, 26, 33, 39, 43, 46, 52]"
7,4706711dc4e1e16424db9f454a1f3b092b972785,SVD-LLM: Truncation-aware Singular Value Decomposition for Large Language Model Compression,5.824486376386601,0.15818813608491006,0.9862729200174996,111,"[""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[3, 4, 4, 7, 10, 12, 15, 20, 23, 24, 26, 34, 38, 40, 56, 69, 79, 86, 94]"
8,199cbde8658dee02643f0352a62ab51657924d08,Ensemble Learning for Heterogeneous Large Language Models with Deep Parallel Collaboration,3.254179724387553,0.15519519406460186,0.9624226885529995,52,"[""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[0, 0, 2, 4, 4, 5, 7, 8, 10, 12, 17, 22, 25, 29, 31, 32, 37, 43]"
9,830c277b2992f59ec2f21982e245bd1e17dd85ca,Step-level Value Preference Optimization for Mathematical Reasoning,5.866446401785154,0.15494846463757114,0.9220446154293928,60,"[""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[0, 0, 1, 3, 10, 10, 13, 15, 23, 30, 34, 37, 44, 47, 49, 52]"
10,1c66c41ff22adf66bb9b06d87d5a2ab7b8ee8de7,"Large Language Model (LLM) for Telecommunications: A Comprehensive Survey on Principles, Key Techniques, and Opportunities",10.55266707631086,0.15372915170226387,0.974768163223376,132,"[""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[4, 4, 9, 12, 15, 24, 31, 35, 37, 40, 47, 53, 76, 88, 96, 102, 116]"
11,168b0348dd76caf99b687c37aefe95a10664e6de,BoNBoN Alignment for Large Language Models and the Sweetness of Best-of-n Sampling,7.530778550331756,0.15325817410486345,0.9750269350383779,78,"[""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[3, 5, 5, 9, 15, 16, 18, 20, 28, 31, 35, 46, 53, 58, 62, 70]"
12,e3c2c4104ca8923fd58508ab6cb52f5c579a77c9,Scene-LLM: Extending Language Model for 3D Visual Understanding and Reasoning,6.931796759370448,0.14992217550410247,0.968000879997106,105,"[""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[1, 2, 3, 6, 8, 9, 13, 15, 22, 30, 33, 38, 47, 51, 62, 75, 82, 86, 92]"
13,1784c987e681d60c634765fe64c8d9c26f73d5ff,SnapKV: LLM Knows What You are Looking for Before Generation,25.412750849922347,0.14696683325722026,0.9561219850871349,307,"[""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[4, 6, 20, 26, 27, 32, 50, 58, 79, 88, 130, 154, 172, 199, 221, 236, 257, 277]"
14,b7f46c9f01d9f649d18b709e2e88b3b97bebd016,"RepairAgent: An Autonomous, LLM-Based Agent for Program Repair",10.726588910255257,0.14149141460174583,0.9926073406986734,147,"[""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[7, 8, 10, 16, 16, 20, 24, 30, 34, 38, 43, 49, 59, 73, 80, 96, 107, 116, 131]"
15,b07880f7b932c7dc8b1091c6c80c9de3e7d64185,Regularizing Hidden States Enables Learning Generalizable Reward Model for LLMs,10.118634825086195,0.1412982097340991,0.9511201347117119,87,"[""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[1, 3, 6, 12, 20, 20, 24, 27, 35, 39, 42, 54, 64, 67, 70, 76]"
16,f57edfe71eb044da97b56cf39157002174644352,FedBiOT: LLM Local Fine-tuning in Federated Learning without Full Model,9.377379634842994,0.13905067825083492,0.9574157255722449,75,"[""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[2, 5, 6, 8, 15, 21, 24, 26, 29, 37, 40, 48, 55, 59, 65, 68]"
17,5354281f118de985fe2bbd1a0b45862d363a5202,T2V-Turbo: Breaking the Quality Bottleneck of Video Consistency Model with Mixed Reward Feedback,5.596256613066259,0.137102068773392,0.9431836202267806,52,"[""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[0, 3, 3, 4, 6, 9, 11, 17, 19, 23, 28, 28, 30, 36, 39, 43, 45]"
18,8d5bc0b0ddca8740e4bec70231b7f0d12ded3d5d,Sycophancy to Subterfuge: Investigating Reward-Tampering in Large Language Models,8.510867974459124,0.13430830681103567,0.9753340013544327,69,"[""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[3, 6, 7, 11, 16, 19, 20, 23, 25, 28, 34, 39, 47, 51, 54, 60]"
19,c119bc07d5e9e2bc4e99b9d48c4a9bc7f49763ae,Direct Preference Optimization of Video Large Multimodal Models from Language Model Reward,9.959075084623114,0.13421781177281436,0.9461464677287853,105,"[""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[1, 2, 2, 7, 8, 14, 16, 24, 29, 38, 44, 47, 55, 65, 76, 84, 89, 93, 97]"
20,8f2254fb38cfc8f79524fd1cd2609124808f2c8c,Token-level Direct Preference Optimization,8.527275363383671,0.13331073498282772,0.9538013747907297,87,"[""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[1, 3, 6, 7, 10, 11, 21, 25, 27, 27, 34, 39, 48, 56, 62, 65, 68, 74]"
21,dd416e705a68419edb1cb840a6daa43cc8822c2b,Optimization Methods for Personalizing Large Language Models through Retrieval Augmentation,8.306498946102467,0.13307369425075813,0.9761132017651436,82,"[""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[5, 6, 10, 11, 11, 14, 17, 21, 23, 26, 28, 41, 46, 53, 59, 61, 68, 74]"
22,adc8c71591ee5b043447a7d7db8ae09a8a9f1251,Interpretable Preferences via Multi-Objective Reward Modeling and Mixture-of-Experts,34.41138301532183,0.13259976849630836,0.953674869562277,254,"[""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[9, 18, 24, 33, 64, 71, 77, 88, 104, 129, 137, 165, 189, 203, 211, 227]"
23,5c9eec060bd9b7af1b8f71a18c0402de3dc98388,Robust Preference Optimization through Reward Model Distillation,5.724241240036056,0.13222349764460947,0.9765198970249352,52,"[""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[2, 6, 6, 6, 9, 12, 12, 14, 16, 21, 24, 24, 31, 35, 36, 38, 47]"
24,0f0d757e764a7f21d7aaa329c835571b247dd937,QServe: W4A8KV4 Quantization and System Co-design for Efficient LLM Serving,16.612109070871085,0.13213898896434162,0.9507936288362119,131,"[""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[2, 8, 12, 15, 20, 29, 39, 44, 49, 59, 74, 77, 96, 102, 105, 115, 125]"
25,78fbb6e7a1c568a04e8c935aa9909d0c942ea5f6,Executable Code Actions Elicit Better LLM Agents,16.36701358243897,0.13188091410554204,0.9825109044855777,246,"[""2024-02-01"", ""2024-03-01"", ""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[5, 8, 11, 13, 18, 22, 28, 34, 47, 65, 69, 77, 80, 91, 106, 128, 144, 164, 177, 199, 213]"
26,c3f1fae241a3c2449e675ab750873d800f95513c,SimPO: Simple Preference Optimization with a Reference-Free Reward,81.62051985896551,0.12976993860455702,0.9631884517660781,667,"[""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[20, 48, 64, 82, 110, 171, 186, 210, 228, 282, 324, 358, 442, 489, 518, 546, 594]"
27,3b47f85df53eb5cdc98a95de615b8a076fbf3adf,Understanding Large-Language Model (LLM)-powered Human-Robot Interaction,8.49098275756604,0.12870839942300513,0.9598191452423772,102,"[""2024-02-01"", ""2024-03-01"", ""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[1, 1, 5, 6, 10, 14, 16, 16, 20, 25, 29, 33, 41, 48, 59, 71, 77, 83, 88, 95, 97]"
28,1e53e98e8709748a6385137d8f240787c12fcfd4,RLHF Workflow: From Reward Modeling to Online RLHF,22.55181711667554,0.1248587644294083,0.9719482672214024,176,"[""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[11, 19, 20, 21, 34, 48, 54, 56, 59, 74, 82, 87, 107, 129, 135, 142, 154]"
29,5c7f465d162aade4a4c0eefb02fd7aadeebdaf58,LLM Evaluators Recognize and Favor Their Own Generations,31.904320296702988,0.12238551354933593,0.9722062755302181,281,"[""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[6, 12, 29, 39, 49, 57, 74, 84, 93, 94, 110, 127, 148, 171, 189, 205, 217, 239]"
30,dbf829c977c121c3704d070d7800d29fe5914756,LLM Inference Unveiled: Survey and Roofline Model Insights,12.304045939621734,0.12053164582292492,0.9423188077256481,118,"[""2024-03-01"", ""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[1, 3, 5, 8, 11, 16, 18, 25, 32, 39, 45, 51, 61, 70, 78, 87, 92, 94, 100, 108]"
31,2433170286f1adf55670dc68ce73d816e1ccb0be,Aligning to Thousands of Preferences via System Message Generalization,8.504916885590488,0.1204830120349803,0.9281648811135598,60,"[""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[0, 4, 6, 10, 10, 17, 18, 19, 21, 30, 34, 36, 42, 46, 46, 47, 53]"
32,c78350e81298ca87bc1d59b466fa40081232caaa,Teaching Large Language Models to Reason with Reinforcement Learning,13.665950663476366,0.12037650391592702,0.9731102546386702,125,"[""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[6, 9, 12, 17, 20, 22, 26, 38, 39, 42, 44, 51, 57, 64, 81, 95, 98, 104, 108]"
33,8fbf2eb4587b5c271979c3f96eee1b109496143e,QuIP#: Even Better LLM Quantization with Hadamard Incoherence and Lattice Codebooks,17.49972349263759,0.11957425619620667,0.973199414280041,175,"[""2024-03-01"", ""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[6, 9, 10, 18, 23, 31, 34, 40, 50, 53, 58, 65, 77, 88, 95, 121, 132, 135, 142, 157]"
34,ebd1c04c61f73f46def3305ca11d038c46665b65,Contrastive Preference Optimization: Pushing the Boundaries of LLM Performance in Machine Translation,31.383556874689045,0.11513546696612288,0.9574269801651997,327,"[""2024-02-01"", ""2024-03-01"", ""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[2, 7, 10, 17, 29, 48, 58, 66, 79, 105, 111, 122, 127, 155, 171, 190, 219, 243, 257, 264, 280]"
35,b16cbdacf53ab4870ce7645d899c7e9e6f41c51e,Is DPO Superior to PPO for LLM Alignment? A Comprehensive Study,30.75327473011081,0.11360848245374915,0.965686876991169,214,"[""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[5, 19, 32, 38, 43, 50, 66, 75, 79, 82, 102, 119, 126, 147, 165, 173, 179, 196]"
36,9732c864d1d4161fcb106f2961d9a80dd4fffc9a,Dense Reward for Free in Reinforcement Learning from Human Feedback,5.56838684755287,0.11308139993236695,0.9569087022011793,52,"[""2024-02-01"", ""2024-03-01"", ""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[1, 1, 2, 4, 6, 9, 10, 13, 15, 17, 20, 20, 22, 25, 28, 31, 40, 42, 44, 46, 47]"
37,0c43750030198dbe7fe164e1ce743ec64427bca1,Scaling Laws for Reward Model Overoptimization in Direct Alignment Algorithms,16.36214023077926,0.11305031103930542,0.9458032303659532,88,"[""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[9, 11, 13, 15, 29, 31, 33, 36, 46, 51, 52, 63, 71, 73, 74, 82]"
38,8e9088c102b3714ae4e5cac7ced93a59804bfc7c,RewardBench: Evaluating Reward Models for Language Modeling,41.416681063072375,0.11131751593676503,0.9321900470152257,302,"[""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[8, 12, 17, 32, 45, 55, 73, 104, 118, 127, 136, 160, 182, 195, 222, 241, 249, 258, 268]"
39,14191e9f12913ad8c7ac6e1188682afac04aad09,AnyGPT: Unified Multimodal LLM with Discrete Sequence Modeling,22.42437993715047,0.11064501753280782,0.9500858170598433,175,"[""2024-03-01"", ""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[6, 7, 9, 15, 23, 31, 38, 52, 64, 71, 78, 82, 88, 106, 117, 129, 140, 147, 158, 164]"
40,0fa0a76ca02493d7f67e93e1c00489b863716c0a,LLM-Ensemble: Optimal Large Language Model Ensemble Method for E-commerce Product Attribute Value Extraction,6.6496507153877085,0.11048250743399195,0.9439528626233522,53,"[""2024-03-01"", ""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[1, 3, 5, 5, 7, 9, 11, 14, 16, 18, 21, 26, 29, 31, 35, 42, 42, 43, 45, 48]"
41,42ee90ce864f1cb2a865f554fc3c6531d0ea34d3,ODIN: Disentangled Reward Mitigates Hacking in RLHF,10.390560674792917,0.11045934860999626,0.9735365733560375,89,"[""2024-03-01"", ""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[5, 5, 6, 11, 17, 18, 18, 24, 27, 29, 31, 35, 42, 46, 52, 58, 66, 71, 73, 77]"
42,57e7af0b69325fafb371ef5d502e39ef9c90ef7e,Medusa: Simple LLM Inference Acceleration Framework with Multiple Decoding Heads,46.44312324599196,0.10757093385327868,0.9681598405296562,412,"[""2024-02-01"", ""2024-03-01"", ""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[5, 21, 29, 39, 51, 72, 87, 102, 110, 144, 155, 161, 172, 200, 225, 244, 281, 310, 325, 340, 368]"
43,5e71d0e85f65a1c0fb2af7bff281209122c58932,"When Scaling Meets LLM Finetuning: The Effect of Data, Model and Finetuning Method",27.04719912763675,0.10555087875939798,0.9647775339640114,199,"[""2024-03-01"", ""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[10, 12, 15, 24, 34, 45, 51, 57, 70, 78, 85, 92, 105, 112, 123, 142, 157, 166, 174, 182]"
44,50fe40b35d376d000a70a25ab2f9b6e6b6b336d6,DrEureka: Language Model Guided Sim-To-Real Transfer,12.699363202465822,0.10129328834139774,0.9422558311324148,58,"[""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[6, 7, 10, 17, 23, 25, 26, 27, 30, 32, 37, 42, 44, 48, 51, 54]"
45,4e274196324bad3e750e83235516af06733e701d,Unfamiliar Finetuning Examples Control How Language Models Hallucinate,12.374432510994877,0.1000807099185245,0.8890163897430097,73,"[""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[0, 0, 5, 11, 15, 16, 19, 31, 36, 38, 38, 47, 47, 50, 55, 57, 59, 63, 67]"
46,e53aa81923958e8e247bb9d09250b8ccf0848513,Arithmetic Control of LLMs for Diverse User Preferences: Directional Preference Alignment with Multi-Objective Rewards,17.12470260782763,0.0972898917253965,0.9361746704350717,110,"[""2024-03-01"", ""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[3, 5, 8, 16, 25, 27, 30, 34, 46, 49, 49, 51, 61, 65, 68, 82, 87, 93, 94, 95]"
47,b46d05bcf42295b872f3cebf875643d2e66496a4,Direct Language Model Alignment from Online AI Feedback,30.84232648086587,0.09587544775859341,0.9374534040524368,193,"[""2024-03-01"", ""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[5, 7, 15, 32, 44, 51, 52, 65, 80, 84, 88, 89, 106, 118, 127, 141, 153, 159, 163, 170]"
48,250430f92bc02b99161dcf915d13eb102b3f1bf2,Large Language Model (LLM) AI text generation detection based on transformer deep learning algorithm,13.25952628223109,0.0844050079169772,0.8537802359417486,56,"[""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[1, 2, 12, 15, 17, 21, 24, 27, 36, 36, 36, 36, 38, 40, 44, 47, 49, 49]"
49,04d64be16fb402f28348faffef484bd419c8bd8f,Self-Rewarding Language Models,74.82787602191316,0.08335395799620773,0.9170547191146426,404,"[""2024-02-01"", ""2024-03-01"", ""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[10, 31, 37, 57, 86, 114, 127, 141, 155, 192, 204, 216, 225, 247, 267, 281, 300, 323, 328, 333, 355]"
50,67f03ac399693393116076c0b8ec8ea05b910685,WARM: On the Benefits of Weight Averaged Reward Models,29.148695213040103,0.0746415278392572,0.893981088714915,123,"[""2024-02-01"", ""2024-03-01"", ""2024-04-01"", ""2024-05-01"", ""2024-06-01"", ""2024-07-01"", ""2024-08-01"", ""2024-09-01"", ""2024-10-01"", ""2024-11-01"", ""2024-12-01"", ""2025-01-01"", ""2025-02-01"", ""2025-03-01"", ""2025-04-01"", ""2025-05-01"", ""2025-06-01"", ""2025-07-01"", ""2025-08-01"", ""2025-09-01"", ""2025-10-01""]","[6, 11, 18, 24, 32, 44, 48, 52, 59, 72, 74, 75, 78, 86, 90, 98, 102, 105, 109, 112, 113]"
